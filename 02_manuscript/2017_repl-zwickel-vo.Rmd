---
title             : "Gaze cueing in naturalistic scenes under top-down modulation - A conceptual replication"
shorttitle        : "Gaze cueing in naturalistic scenes"

author:
  - name          : "Jonas Großekathöfer"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Marcusstraße 9-11, 97070 Würzburg"
    email         : "jonas.grossekathoefer@uni-wuerzburg.de"
  - name          : "Kristina Suchotzki"
    affiliation   : "1"
  - name          : "Matthias Gamer"
    affiliation   : "1"  

affiliation:
  - id            : "1"
    institution   : "Julius-Maximilian University, Würzburg"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Humans as social beings rely on information provided by conspecifics. One important signal in social communication is eye gaze. The current study (n=90) sought to replicate and extend previous findings of attentional guidance by eye gaze in complex everyday scenes. In line with previous studies, longer, more and earlier fixations for objects referenced by gaze were observed in free viewing conditions. To investigate how robust this prioritization is against top-down modulation, half of the observers receive a memory task that required to scan the whole scene instead of exclusively focusing on *referenced* objects. Interestingly, similar cueing effects occurred in this condition. Moreover, the human beings depicted in the scene received a large amount of attention even though they were irrelevant to the current task. These results indicate that the mere presence of other human beings as well as their gaze orientation have a strong impact on attentional exploration.


keywords          : "keywords"
wordcount         : "?wordcountaddin"

bibliography      : 
  - "r-references.bib"
  - "../2017_repl-zwickel-vo.bib"

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            :
  papaja::apa6_pdf:
    keep_tex: TRUE
                      
---

```{r load_packages, include = FALSE}

library("papaja")
library("tidyverse")
library("car")
library("afex")
library("ggpubr")

```

```{r paths}

rm(list=ls())

pathMEM <- "../01_data/Memory/"
pathET <- "../01_data/prot/"
pathFB <- "../01_data/FB/"

```

```{r Generate prot}

```

```{r Check stimuli}

```

```{r Check baseline quality}

```

```{r Analyze fixations}

```

```{r Reading eye tracking data in, warning = FALSE, message = FALSE}

# ALL EYE TRACKING DATA
vpn <- paste0("vpja",ifelse(c(1:78,81:96)<10,"0",""),c(1:78,81:96))
bed <- rep(c("free","mem"),47)

# ORIGINALLY ACQUIRED DATA
#vpn <- paste0("vpja",ifelse(c(1:78)<10,"0",""),c(1:78))
#bed <- rep(c("free","mem"),39)

bed <- bed[!(vpn %in% "vpja23")]  # missing data
vpn <- vpn[!(vpn %in% "vpja23")]  

# Loop over subjects
erg <- numeric(); nvalid <- numeric(); cleantime <- numeric()
for (vp in vpn) {
  #  print(vp)

  prot <- read.csv2(paste0(pathET,vp,"_Fixations.csv"))

  # Restrict to trials with valid baseline?
  nvalid <- c(nvalid,sum(prot$blok==1))
  prot <- prot[prot$blok==1,]

  cleantime <- c(cleantime,mean(prot$cleantime))

  erg <- rbind(erg,apply(prot[,8:ncol(prot)],2,mean,na.rm=TRUE))
}

df.w.et <- data.frame(code=vpn,group=bed,nvalid,cleantime,erg)


df.l.et <- gather(df.w.et, key, value, fix.face:sac.bnongaze, factor_key=TRUE) %>%
  mutate(
    key = as.character(key),
    fixations =
      as.factor(
        ifelse(startsWith(key, "fix."), "fix",
             ifelse(startsWith(key, "fixn."), "fixn",
                    ifelse(startsWith(key, "fixlat."), "fixlat",
                           ifelse(startsWith(key, "sac."), "sac", NA))))),
    region =
      as.factor(
        ifelse(endsWith(key, ".face"), "face",
               ifelse(endsWith(key, ".body"), "body",
                      ifelse(endsWith(key, ".gaze"), "gaze",
                             ifelse(endsWith(key, ".nongaze"), "nongaze",
                                    ifelse(endsWith(key, ".pgaze"), "pgaze",
                                           ifelse(endsWith(key, ".fgaze"), "fgaze",
                                                  ifelse(endsWith(key, ".bgaze"), "bgaze",
                                                         ifelse(endsWith(key, ".pnongaze"), "pnongaze",
                                                                ifelse(endsWith(key, ".fnongaze"), "fnongaze",
                                                                       ifelse(endsWith(key, ".bnongaze"), "bnongaze",NA)))))))))))) %>%
  arrange(code)

rm(prot, bed, cleantime, nvalid, vp, vpn, erg)

```

```{r Reading memory data in, warning = FALSE, message = FALSE}

# ALL MEMORY DATA
vpn <- paste0("vpja",ifelse(c(1:78,81:96)<10,"0",""),c(1:78,81:96))
bed <- rep(c("free","mem"),47)

# ORIGINALLY ACQUIRED DATA
#vpn <- pasteo("vpja",ifelse(c(1:78)<10,"0",""),c(1:78))
#bed <- rep(c("free","mem"),39)

# Loop over subjects
erg <- numeric()
for (vp in vpn) {
  # print(vp)

  prot <- read.csv2(paste0(pathMEM,vp,".csv"))

  # Item recalled
  gaze <- sum(prot$memgazedat)
  nogaze <- sum(prot$memnongazedat)

  erg <- rbind(erg,c(gaze,nogaze))
}

df.w.mem <- data.frame(code=vpn,bed,erg)               
names(df.w.mem) <- c("code","bed","memgaze","memnogaze")

rm(gaze, nogaze, erg, prot, bed, vp, vpn)

```

```{r Reading questionnaire data in, warning = FALSE, message = FALSE}

df.w.demo <- read_csv2(paste0(pathFB,"Projektarbeit_Dateneingabemaske.csv")) %>%
  transmute(
    vp = as.factor(VP_Nr),
    sex = as.factor(Demo_Sex),
    age = Demo_Alter,
    aq_social = ifelse((5-AQK_1) < 3, 1, 0) + ifelse((5-AQK_7) < 3, 1, 0) + ifelse(AQK_8 < 3, 1, 0) + ifelse((5-AQK_10) < 3, 1, 0) + ifelse((5-AQK_11) < 3, 1, 0) + ifelse(AQK_13 < 3, 1, 0) + ifelse((5-AQK_14) < 3, 1, 0) + ifelse((5-AQK_20) < 3, 1, 0) + ifelse((5-AQK_24) < 3, 1, 0) + ifelse((5-AQK_28) < 3, 1, 0) + ifelse((5-AQK_31) < 3, 1, 0), # 5- 'item' for reversed items, then if 1/2 -> 1, 3/4 -> 0  
    aq_imagination = ifelse((5-AQK_3) < 3, 1, 0) + ifelse((5-AQK_5) < 3, 1, 0) + ifelse((5-AQK_6) < 3, 1, 0) + ifelse((5-AQK_9) < 3, 1, 0) + ifelse((5-AQK_16) < 3, 1, 0) + ifelse((5-AQK_17) < 3, 1, 0) + ifelse((5-AQK_18) < 3, 1, 0) + ifelse((5-AQK_22) < 3, 1, 0) + ifelse((5-AQK_23) < 3, 1, 0) + ifelse((5-AQK_26) < 3, 1, 0) + ifelse((5-AQK_32) < 3, 1, 0) + ifelse((5-AQK_33) < 3, 1, 0),
    aq_communication = ifelse(AQK_2 < 3, 1, 0) + ifelse(AQK_4 < 3, 1, 0) + ifelse(AQK_12 < 3, 1, 0) + ifelse(AQK_15 < 3, 1, 0) + ifelse(AQK_19 < 3, 1, 0) + ifelse(AQK_21 < 3, 1, 0) + ifelse(AQK_25 < 3, 1, 0) + ifelse(AQK_27 < 3, 1, 0) + ifelse(AQK_29 < 3, 1, 0) + ifelse(AQK_30 < 3, 1, 0),
    aq_sumscore = ifelse((5-AQK_1) < 3, 1, 0) + ifelse(AQK_2 < 3, 1, 0) + ifelse((5-AQK_3) < 3, 1, 0) + ifelse(AQK_4 < 3, 1, 0) + ifelse((5-AQK_5) < 3, 1, 0) + ifelse((5-AQK_6) < 3, 1, 0) + ifelse((5-AQK_7) < 3, 1, 0) + ifelse(AQK_8 < 3, 1, 0) + ifelse((5-AQK_9) < 3, 1, 0) + ifelse((5-AQK_10) < 3, 1, 0) + ifelse((5-AQK_11) < 3, 1, 0) + ifelse(AQK_12 < 3, 1, 0) + ifelse(AQK_13 < 3, 1, 0) + ifelse((5-AQK_14) < 3, 1, 0) + ifelse(AQK_15 < 3, 1, 0) + ifelse((5-AQK_16) < 3, 1, 0) + ifelse((5-AQK_17) < 3, 1, 0) + ifelse((5-AQK_18) < 3, 1, 0) + ifelse(AQK_19 < 3, 1, 0) + ifelse((5-AQK_20) < 3, 1, 0) + ifelse(AQK_21 < 3, 1, 0) + ifelse((5-AQK_22) < 3, 1, 0) + ifelse((5-AQK_23) < 3, 1, 0) + ifelse((5-AQK_24) < 3, 1, 0) + ifelse(AQK_25 < 3, 1, 0) + ifelse((5-AQK_26) < 3, 1, 0) + ifelse(AQK_27 < 3, 1, 0) + ifelse((5-AQK_28) < 3, 1, 0) + ifelse(AQK_29 < 3, 1, 0) + ifelse(AQK_30 < 3, 1, 0) + ifelse((5-AQK_31) < 3, 1, 0) + ifelse((5-AQK_32) < 3, 1, 0) + ifelse((5-AQK_33) < 3, 1, 0))

```

# Introduction
Humans in their social environment rely on the information conspecifics provide. This does not only hold for reading explicit signals, as in conversations, but also for implicit signals, as in gazes. Specifically, if an individual looks into a specific direction, this information is often read spontaneously and redirects the observers attention towards the referred object or location. The process of following someones gaze is can be referred to as joint attention. These attentional shifts are crucial for joint attention.

  <!-- gaze cuing to joint attenion & social attention -->
The most used paradigm to investigate these attentional shifts is the so-called gaze-cueing paradigm [@Friesen1998; @Driver1999; @Langton2000]. These studies show that perceived gaze cues lead to a reflexive attentional shifts, which can result in processing benefit for specific locations [for a very recent study see @Langton2017]. Even though gaze cues are crucial for joint attention, the standard gaze-cueing paradigm is criticized for lacking ecological validity [for an overview see: @Risko2012], because (among others) these studies use isolated heads [@Friesen1998; @Langton2000] or even cartoon heads [@Driver1999; @Ristic2005] as gaze cues. For example, in an recent study @Hayward2017 did not find reliable links between classical laboratory gaze cueing tasks and real social engage.  
The relevance of ecological valid stimuli is a core aspect of social attention research, which provides a bigger framework for gaze cueing [@Itier2009]. Social attention research describes attentional consequences of social interactions and focuses often on similarities and differences of different types of social stimuli [@Risko2012], from real human interactions [for example: @Laidlaw2011; @Freeth2013a] to highly controlled laboratory settings with isolated faces as stimuli [for example: @Langton2017].<!--The main finding of this research line is, that some research findings related to social stimuli do not extend to the real world. Researches must be sensible to these differences when generalizing laboratory findings [@Jarick2015; @Hayward2017; for an overview see: @Risko2016].
Additionally, laboratory studies showed, that joint attention can not only be induced by the gaze [for an detailed overview see: @Frischen2007a], but also from the body or the head itself [@Lawson2016].-->

  <!-- social attention -->
<!--Birmingham2008 und Birmingham2009b als vormacher und grundsätzliche Idee das problem anzugehen, weitere Ansätze-->To account for these issues in gaze cuing patadigms @Zwickel2010 conducted a joint attention study using a so called free-viewing paradigm with a full person as a directional cue.
A main aspect of their study was that participants had no explicit task to fulfill. @Zwickel2010 argue, that the lack of a specific task results in more naturalistic viewing behavior and therefore adds more ecological validity to classical gaze cuing paradigms. They presented their observers multiple scenes for several seconds. The scenes contained a reference, either a person or a loudspeaker, and two objects. The authors of the study made sure, that the relevant objects were not placed in prominent locations, so that the object is not highlighted by positon itself. In each scene, only one of the objects was referenced either by the oriented person or by the loudspeaker.
They showed that observers of the scene fixated the referenced object remarkably earlier, more often and overall longer then the not referenced object. However, the prioritization of the object occured only when the person referenced the object. By showing that leaving saccades from the head (but not from the loudspeaker) landed most often onto the referenced object the results give direct support for the relation between cue type and object role.
The attentional focus of the person in the scene guided attentional distribution of the observer. Interestingly, the same was not true for the loudspeaker. The referenced objects were not just focused because they might have been salient by themselves (due to e.g. positioning), but became more salient merely by the persons reference.<!--detailierter?!--> <!--Additionally finding is in line with general predictions from the social attention approach. First, that social stimuli are prioritized was confirmed by the results, the most prioritized region was still the head of the shown person.-->After all, @Zwickel2010 provide evidence that joint attention as consequence of gaze cues happen spontaneously and that it has high relevance even in more naturalistic situations.<!--softerer übergang pls-->
  
  <!-- research motivation -->
Unclear remains, how robust these joint attenional effects are. So, this conceptual replication of Zwickel and Võ's work aims at answering multiple research questions regarding joint and social attention, including the replication of Zwickel and Võ's [-@Zwickel2010] findings and extending this line of research.
  
  <!-- extended research | Top-Down Modulations-->
To extend this line of research the influence of top-down modulations on joint and social attention in naturalistic scenes is investigated. Earlier research showed, that social attention is influenced by multiple factors like social status [@Foulsham2010] or expectations [@Perez-Osorio2015]. These studies have in common that they manipulate viewing behavior of the observer by manipulating the stimuli in one or the other way. For example, @Foulsham2010 build the stimulus set from stimuli that were previously rated for social status and confirmed the predicted shift in attention with eye-tracking measueres.
In the present study, however, observers receive a very explicit manipulation. In the *explicit-encoding group* the observers received the information that a memory test is following the experimental part. In contrast, in the *free-viewing group* observers got instructed right before the memory task. Besides that manipulation all observer did exactly the same experiment (with balanced and randomized stimuli). By instruction objects became relevant for succeeding in the memory task. Conclusively, attention towards the person would be inefficient. The manipulation is thought to induce a more explicit and systematic encoding of the presented scenes, specifically towards objects.
Additionally, the consequences for latter cognitive processes, here memory effects, are examined for the different roles of the objects. Observers from the *free-viewing group* who did not receive any top-down modulation in advance should provide an unaffected viewing behavior, just like @Zwickel2010 demonstated. Both groups had to recall as many as things as possible from the scenes in a free-recall memory test. With this manipulation it is thought to demonstrate top-down influence on social attenion aspects, but also its influence on joint attention.
As @Zwickel2010 showed, a person in a scene influences the viewing behavior of observers spontaneously and without further instruction or manipulation. In the given study, the motivation for the manipulation of the instructions for the memory test was twofold. First, it is thought to test robustness of the social and joint attention effects and second joint attentional effects on memory can be observed. The influence the manipulation is expected to reduce spontaneous viewing behavior and foster a more systematic processing of the scene. It is important to note, that it is not expected that the influence of the presence of the person vanishes completely for social and joint attentional effects due to top-down modulation. It is supposed to be weaker, because it does not represent the optimal strategy for the observer. Therefore the voluntary part of the scene processing might be overwritten. But as social and joint attentional effects are expected to be (partially) independent of volition and occure spontaneously and reflexive the effects should still be visible regardless for the social attention part and also for the joint attention part of this study. Specifically, prioritization effects for the head should be smaller but still visible in the *explicit-encoding group*. For the joint attention measures a decreased prioritization for the referenced object is expected for the *explicit-encoding group* is decreased compared with the not gazed-a object. An optimal strategy for observer in the *explicit-encoding group* would be to ignore completely the person in the scene, resulting in smaller differences in attentional prioritization between the two object roles.
Additionally, memory effects sensitive for the role of the object were examined, to answer the question whether more attentional resources on a object pays off with enhanced memorability. This is mainly interesting for the free-viewing group with the unbiased viewing behavior, as it is expected that both objects bind comparable amount of attention due to the more systematic processing in the explicit encoding group.

<!-- @Zwickel2010 had very little power in their study, with n = 16 participants -- zu unserer Power was schreiben?!-->
@Zwickel2010 used computer generated stimuli<!--, slightly in contrast to their motivation to provide a naturalistic setup-->. Here, stimuli that are more naturalistic and a bigger sample size is used.
Consequently, real photographs are chosen over computer rendered scenes. As often, by being more naturalistic experimental control is reduced. The consequences are hold to a minimum by producing the stimuli the same way. In particular, each scene was photographed four times, with the individual looking twice to the left and right to each object. Although, as much as possible was controlled for in the photographs, real photographs contain small unavoidable changes. Whereas @Zwickel2010 rotate the figure in the computer rendered scene, they have complete control of all the changes, e.g. angel of the body or facial expression. Here, another photography was taken. As consequence, for example, the body orientation within the four balanced scenes can not be perfectly controlled and might differ slightly between photographs within scenes.<!-- nochmal sagen, warum das torztdem toll ist? -->
With higher power and more naturalistic stimuli this study will <!-- still, however, nevertheless, yet, regardless, even though, despite --> underline @Zwickel2010 findings. However, it is presumed that the effect showed by @Zwickel2010 is genuine for social stimuli, therefore there is no non-social condition comparable to the loudspeaker-condition.  

  <!-- Hypothesis -->
<!-- alter baustein: First, for joint attention, it is presumed to replicate the main effects of a persons presence on the observer described by @Zwickel2010. It is therefore hypothesized that the gaze of the person in the scene leads to prioritization for the *referenced*/referenced object. The prioritization can be seen in earlier, more and longer fixations. In line with @Zwickel2010 it is also expected, that saccades leaving from the head are more likely to move to the *referenced* object. -->
        <!-- joint attention/gaze following -->
The foundation of this study is to examine top-down modulation on gaze cueing and to replicate the findings from [@Zwickel2010].  
*H1*. Consequently, a prioritization for the *referenced* objects is predicted. In line with @Zwickel2010, this  prioritization is measured in multiple ways. First there should be an early fixation bias towards the *referenced* object. During presentation time, the total time that the *referenced* object is fixated should be prolonged, with more fixations as well. For saccades it is expected, that leaving from the head it is more likely to move to the *referenced* object, in contrast to the not-*referenced* object.<!--Main effect icond, Anova-->  
*H2*. New, compared to Zwickel and Võ's [-@Zwickel2010] study, is the instruction condition. For gaze-following it is expected that the exclusive prioritization for the *referenced* object will decrease for subjects in explicit-encoding group, due to the instruction of the memory test and a more explicit and systematic processing of the scene. This means smaller differences in the fixation measurements are expected. For leaving saccades it is also expected that the under H1 stated effect decreases. <!--1st: (Interaction group:icond)
(?!Hypothese zu Gruppen, dass explicit mehr focus auf Gegensätnde richtet, da anweisung? (Maineffect group) -->  
*H3*. For the follow-up memory test it is assumed, that observers with announced memory test (in the *explicit-encoding group*) will recall more items, because they process the scenes more thorough. Additionally it is expected, that in the free-recall condition *referenced* objects are better recalled then not-*referenced* objects.
        <!-- social attention -->
*H4*. Additionally to the joint attentional effects stated in H1, the basic effects of social attention are expected. This means, that the head will be prioritized over the body. This prioritization can be measured, in multiple ways. Again, it is expected, that first fixation fall earlier on the head, that it is fixated longer and more often then the body. Additionally, fixations occur earlier on the head, then on the *referenced* object, because the gaze-cue needs to be processed in advance.<!--gibt's gar keine Analyse für!!!-->  
*H5*. Due to the instruction of the memory test, and the assumed change in processing the scene, the viewing behavior should change for social stimuli. Due to explicit encoding, it is expected that natural viewing behavior that is known to prioritize the head is reduced and therefore the head looses some of its salience. As a consequence, the head should be prioritized stronger in the *free-viewing group* compared to the *explicit-encoding group*, resulting in longer fixations, faster fixations and more fixations. 

# Methods
<!-- We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants
In this study `r length(df.w.demo$vp)` observers (`r length(df.w.demo$sex[df.w.demo$sex==1])` female and `r length(df.w.demo$sex[df.w.demo$sex!=1])` male) between `r min(df.w.demo$age)` and `r max(df.w.demo$age)` years (M = `r round(mean(df.w.demo$age),2)`, SD = `r round(sd(df.w.demo$age),2)`) participated voluntarily. All observer had normal or corrected vision and were recruited at the University of Würzburgs online subject pool or by blackboard. For participation observers received study credit or 5€. One observer was excluded due to missing data.

## Stimuli and Apparatus
The experimental stimuli consisted of 26 different scenes with a single individual in the center looking at one of two objects of interests in the right or left half of the photography. The direction of the gaze cue and the place of the objects were balanced, creating 104 unique naturalistic scenes in the end. For each participant, a set was randomly generated from this pool containing each scene only once, resulting in 26 trials with exclusive scenes. Eye movements were recorded with an EyeLink1000 tower system, sampling at 1000 Hz.

## Design & Procedure
A two-level (instruction: free viewing / explicit encoding) between subjects factor and a two-level (reference: cued/uncued) within subjects factor was manipulated in the experiment. After giving full informed consent, the eye-tracker was calibrated for each observer. Half of the observers were then manipulated by getting told, that  there is a follow-up memory test. The presentation of the stimuli was randomized. In each trial the scene was present for 10 seconds. Observers were told to look at the scene as they would look at photographs. Inter trial interval was randomized between 2 and 4 seconds. After the last trial participants filled in questionnaires (demographics, autism-questionnaire (short), and Inventar soziale kompetenz). The questionnaire session was also used as a puffer for the following memory task, to prevent primacy and recency effects. Then observers were asked to recall as many items as possible in a free recall memory-test. Afterwards participants received their credit.


## Data analysis
Regions-of-Interest were hand-drawn around the relevant objects and the face and body of the individual in the center. These ROIs were color-coded for cued and uncued objects and also for the head and body of the individual on the photography to determine gaze locations. <!-- Outlier detection?!!? -->

`r cite_r("r-references.bib")` is used for all analyses.


# Results
Prioritization of the ROIs in the scene were measured in multiple ways. 

## Joint attention/ gaze following

As a measure of prioritization fixation duration, fixation number, fixation latency, as well as leaving saccades are used.

### Fixations
```{r TO-DO: Plots fixations joint, warining = FALSE, message = FALSE}

```

```{r Descriptives fix*, warining = FALSE, message = FALSE}

# Descriptives for fixation chacracteristics for joint attention

dscr.fix.rpl <- df.w.et %>%
  group_by(group) %>%
  summarise_at(vars(fix.face:fixlat.nongaze), funs(mean,sd,se=sd(.)/sqrt(n()))) %>% # mit den funs() die variablen vars(von:bis) berechnen
  gather(key, measure, fix.face_mean:fixlat.nongaze_se) %>% # ins longformat
  mutate(fix = as.factor(map(strsplit(key,"[[:punct:]]"), ~.x[1]) %>% unlist()),
         gazed = map(strsplit(key,"[[:punct:]]"), ~.x[2]) %>% unlist(),
         gazed = as.factor(substring(gazed,1)),
         stat = as.factor(map(strsplit(key,"[[:punct:]]"), ~.x[3]) %>% unlist()),
         key = as.factor("replication")) %>% # 
  select(-measure, everything()) %>% # neusortieren der variablen
  select(key, everything())

dscr.fix.rpl$gazed <- factor(dscr.fix.rpl$gazed, levels=c("face", "body", "gaze", "nongaze"))

dscr.fix.zwckl <- data.frame(group="free",fix=c("fix","fix","fix","fix","fixn","fixn","fixn","fixn","fixlat","fixlat","fixlat","fixlat"), gazed=c("gaze","gaze", "nongaze", "nongaze"), stat=c("mean","se"), measure=c(0.08,.01,.07,.01,5.89,.37,5.24,.34,3588,133,4008,166)) # free = person

```

```{r Anova fixations joint, warning = FALSE, message = FALSE}

# ANOVA Fixations characteristics for joint attention
## 2 (Group) x 2 (Gaze) ANOVA

icond <- gl(2,1,labels=c("cued","uncued")) # within-factor
idata <- data.frame(icond)

for (st in seq(7,16,4)) { # Variables 7:16, every 4th: fix.gaze and fix.nogaze; fixn.gaze and ...
  carmod <- lm(as.matrix(df.w.et[,st:(st+1)]) ~ df.w.et$group)
  #print(colnames(df.w.et[,st:(st+1)]))
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }

rm(carmod, idata, icond, st)

```

#### Fixation duration
<!-- (H1, H2) -->
To quantify and compare prioritization against each object a measure on how big the proportion of the duration of all fixations was for every ROI was calculated. Specifically, the cumulative time a fixation rested on an object was divided by the total time spent fixating any other rest of the scene. By that, a relative measures for fixation duration was gained. It shows a bias towards the *referenced* object, which was fixated longer (see Table/Figure) and confirms [@Zwickel2010]'s findings. As predicted the corresponding ANOVA revealed a significant main effect for reference, `r apa.anova.fix.gaze$full_result$icond` and for condition `r apa.anova.fix.gaze$full_result$df_w_et_group`. Against prediction their was no effect of the two-way interaction, `r apa.anova.fix.gaze$full_result$df_w_et_group_icond`. <!-- was it against pred? -->  <!-- The relative cumulative fixation duration is calculated as time duration on an object divided by--> 


#### Fixation latency
<!-- (H1, H2) -->
An additional measurement of prioritization is fixation latency, that is for each ROI the mean out of all first fixations after stimulus onset<!--besser formulieren!!-->. In line with [@Zwickel2010], an object is fixated earlier when it is *referenced*. But also when the observer was in the explicit encoding condition. The statistical significance is confirmed by an ANOVA: for reference `r apa.anova.fixlat.gaze$full_result$icond` and condition, `r apa.anova.fixlat.gaze$full_result$df_w_et_group`). For fixation latency with a trend(?) for an interaction, `r apa.anova.fixlat.gaze$full_result$df_w_et_group_icond`.

#### Fixation number
<!-- (H1, H2) -->
As a third measurement of prioritization, fixation number, as the count of fixations per ROI during scene presentation, divided by the total number of fixations during scene presentation, was calculated. It shows, that OOI were fixated more often when *referenced* `r apa.anova.fixn.gaze$full_result$icond`, again in line with [@Zwickel2010]. Objects were also more often fixated in the explicit encoding condition`r apa.anova.fixn.gaze$full_result$df_w_mem`, and again against prediction there was no interaction, `r apa.anova.fixn.gaze$full_result$df_w_et_group_icond`.
 

### Saccades

```{r descriptives saccade, include=FALSE}
dscr.sac.rpl <- df.w.et %>%
  group_by(group) %>%
  summarise_at(vars(sac.pgaze:sac.bnongaze), funs(mean,sd,se=sd(.)/sqrt(n()))) %>% # mit den funs() die variablen vars(von:bis) berechnen
  gather(key, measure, sac.pgaze_mean:sac.bnongaze_se) %>% # ins longformat
  mutate(stat = as.factor(map(strsplit(key,"[[:punct:]]"), ~.x[3]) %>% unlist()),
         area = map(strsplit(key,"[[:punct:]]"), ~.x[2]) %>% unlist(),
         area = as.factor(substring(area,1,1)),
         gazed = map(strsplit(key,"[[:punct:]]"), ~.x[2]) %>% unlist(),
         gazed = as.factor(substring(gazed,2)), 
         key = as.factor("replication")) %>% #rausnehmen, zur kontrolle, ob alles passt, was oben läuft.
  select(-measure, everything()) %>% # neusortieren der variablen
  select(key, everything())

dscr.sac.zwckl <- data.frame(key=c("zwickel","zwickel"),group=c("free", "free"),gazed=c("gaze", "gaze", "nongaze", "nongaze"),stat=c("mean", "se"),measure=c(.14,0.01,.09,0.01)) # free = person

```

```{r Matthias plots saccade, include=FALSE, echo = FALSE}
# Plots: Saccade data
'
farben <- c("blue","yellow")
ttxt <- c("Person","Face","Body")

for (i in 1:3) {
  st <- (17:19)[i]

  # Fixation density
  m  <- cbind(apply(df.w.et[df.w.et$group=="free",c(st,st+3)],2,mean),
              apply(df.w.et[df.w.et$group=="mem",c(st,st+3)],2,mean))
  se <- cbind(apply(df.w.et[df.w.et$group=="free",c(st,st+3)],2,sd)/sqrt(sum(df.w.et$group=="free")),
              apply(df.w.et[df.w.et$group=="mem",c(st,st+3)],2,sd)/sqrt(sum(df.w.et$group=="mem")))

  yrng <- c(0,max(m+se))

  x <- barplot(m,beside=TRUE,col=farben,ylim=yrng,xlab="",ylab="% of total fixation time")
  arrows(x,m-se,x,m+se,length=0.03,angle=90,code=3,col="black")
  axis(1,apply(x,2,mean),c("Free viewing","Explicit encoding"),tick=FALSE)

  title(ttxt[i])
}

legend(max(x),max(yrng),c("Cued","Uncued"),fill=farben,xjust=1,yjust=1)

rm(m, se, yrng, x, st, farben, ttxt, i)
'
```

```{r Anova saccades, warning=FALSE, message=FALSE}
# ANOVA Saccades
## 2 (Group) x 2 (Gaze) ANOVA

icond <- gl(2,1,labels=c("cued","uncued")) # within-factor
idata <- data.frame(icond)

for (st in 17:19) {
  carmod <- lm(as.matrix(df.w.et[,c(st,(st+3))]) ~ df.w.et$group)
  #print(colnames(df.w.et[,c(st,(st+3))]))
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }



rm(carmod, idata, icond, st)
```

#### Leaving saccades
<!-- (H1, H2) -->
The second hypothesis predicts, that there are more saccades leaving from the head to the *referenced* object. Furthermore it is claimed, that an interaction between instruction and reference results in increasing differences in the free-viewing condition. An Anova supports the first claim. There is an significant main effect for reference, `r apa.anova.sac.fgaze$full_result$icond`, and also for group,  `r apa.anova.sac.fgaze$full_result$df_w_et_group`. No confirmation was found for the predicted interaction between reference and instruction `r apa.anova.sac.fgaze$full_result$df_w_et_group_icond`.

### Memory
<!-- (H3) -->

```{r plots memory}

```

```{r Anova memory, warning=FALSE, message=FALSE, echo = FALSE}

# Recalled items
# 2 (Condition) x 2 (Gaze) ANOVA (auf erinnerte Details)

imem <- gl(2,1,labels=c("cued","uncued"))
idata <- data.frame(imem)

# Car
carmod <- lm(as.matrix(df.w.mem[,3:4]) ~ df.w.mem$bed)
print(colnames(df.w.mem[c(3,4)]))
print(Anova(carmod, idata=idata, idesign=~imem, type="III"))
anova.mem <- Anova(carmod, idata=idata, idesign=~imem, type="III")
apa.anova.mem <- apa_print(Anova(carmod, idata=idata, idesign=~imem, type="III"), correction="GG", mse = FALSE)

dscr.mem <- df.w.mem %>% summarise(mean(memgaze), sd(memgaze), mean(memnogaze), sd(memnogaze))
dscr.mem.group <- df.w.mem %>% group_by(bed) %>% summarise(mean(memgaze), sd(memgaze), mean(memnogaze), sd(memnogaze))

rm(imem, idata, carmod)
```

The free-recall test showed, that unsurprisingly observers with who received the instruction of the memory test before the free viewing remembered on average 2 items more then observers from the other group. An Anova proved this effect as statistically significant, `r apa.anova.mem$full_result$df_w_mem_bed`. Referencing an OOI did not influence memory performance, `r apa.anova.mem$full_result$imem`. There was also no interaction, `r apa.anova.mem$full_result$df_w_mem_bed_imem`.
The free recall-memory test was applied successful. Observers with instruction performed better in terms of recalling objects from the scenes.

## Social attention
A similar pattern to the OOI can be seen when comparing the head with the body region. Again there were the same measurements to account for prioritization. 

```{r TO-DO: Plots fixations social, warining = FALSE, message = FALSE}

```

```{r Descriptives fixations social, warining = FALSE, message = FALSE}

# Descriptives for fixation chacracteristics for social attention

dscr.fixsoc <- df.w.et %>% summarise(mean(fix.face), sd(fix.face), mean(fix.body), sd(fix.body), mean(fixn.face), sd(fixn.face), mean(fixn.body), sd(fixn.body), mean(fixlat.face), sd(fixlat.face), mean(fixlat.body), sd(fixlat.body))
dscr.fixsoc.group <- df.w.et %>% group_by(group) %>% summarise(mean(fix.face), sd(fix.face), mean(fix.body), sd(fix.body), mean(fixn.face), sd(fixn.face), mean(fixn.body), sd(fixn.body), mean(fixlat.face), sd(fixlat.face), mean(fixlat.body), sd(fixlat.body))
```

```{r Anova fixations social, warning = FALSE, message = FALSE}
# ANOVA Fixations characteristics
## 2 (Group) x 2 (Face/Body) ANOVA

icond <- gl(2,1,labels=c("head","body")) # within-factor
idata <- data.frame(icond)

for (st in seq(5,16,4)) { # Variables 5:16, every 4th: fix.face and fix.noface; fixn.face and ...
    carmod <- lm(as.matrix(df.w.et[,st:(st+1)]) ~ df.w.et$group)
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }


rm(carmod, idata, icond, st)

```
Analysis for the social attention part contained again Anovas for the different dependent variables indicating prioritization.

### Face vs body fixation (H4)
The first measurement shows, that faces were fixated longer then the body  (Table X), `r apa.anova.fix.face$full_result$icond`, but there is no difference between the instruction-groups, `r apa.anova.fix.face$full_result$df_w_et_group`, and no interaction (trend) between the two factors, `r apa.anova.fix.face$full_result$df_w_et_group_icond`.
The same pattern can be seen for fixation number, where there is a strong effect for region, with more fixations on the face, `r apa.anova.fixn.face$full_result$icond` and no difference between the instructions, `r apa.anova.fixn.face$full_result$df_w_et_group`, and no interaction `r apa.anova.fixn.face$full_result$df_w_et_group_icond`.
Latencies of fixation differed also remarkably between head and body, but only for region `r apa.anova.fixlat.face$full_result$icond`. There was neither an effect for instruction, `r apa.anova.fixlat.face$full_result$df_w_et_group` nor was their an interaction, `r apa.anova.fixlat.face$full_result$df_w_et_group_icond`.

### Free-viewing vs explicit-encoding face fixations (H5)
```{r Plots free vs mem face fixations, warning = FALSE, message = FALSE}

# plots

plot.face.free_vs_mem <- df.l.et %>%
  filter(fixations=="fix" & region=="face") %>%
  ggboxplot(x = "fixations", y = "value",
                fill = "group", palette =c("#00AFBB", "#E7B800", "#FC4E07"),
                add = "jitter", shape = "group") #+
  #stat_compare_means()
#plot.face.free_vs_mem

```

```{r T-test face fixations, warning = FALSE, message = FALSE}

# Fixations Face in Free Viewing vs. Explicit Encoding

for (st in seq(5,16,4)) {
  msd <- c(mean(df.w.et[df.w.et$group=="free",st]),sd(df.w.et[df.w.et$group=="free",st]),
           mean(df.w.et[df.w.et$group=="mem",st]),sd(df.w.et[df.w.et$group=="mem",st]))
  teststat <- t.test(df.w.et[,st] ~ df.w.et$group)
  
  assign(paste0("ttest.",colnames(df.w.et)[st]), data.frame(M.free=msd[1],SD.free=msd[2], M.mem=msd[3], SD.mem=msd[4],  df=teststat$parameter, t=teststat$statistic, p=teststat$p.value))
 
  assign(paste0("apa.ttest.",colnames(df.w.et)[st]), apa_print(t.test(df.w.et[,st] ~ df.w.et$group)))
  }


rm(msd, teststat, st) 

```

A t-test between face fixation for the different groups provides information whether faces are differently processed dependent on the instruction observers get. Only fixation latency differed significantly between groups, `r apa.ttest.fixlat.face$full_result`, with faster fixations for the free viewing group. For fixation duration there was only a trend for difference between groups, `r apa.ttest.fix.face$full_result`. And fixation number did not differ, `r apa.ttest.fixn.face$full_result`.   

# Discussion
<!-- Main motivation -->
The main attempt of this study to replicate @Zwickel2010's findings on attentional prioritization from the mere presence of a person in a scene on gaze behavior was successful. 
<!-- replication -->
As in @Zwickel2010 and others studies (for example @Birmingham2008), a strong prioritization can be seen for heads. Accordingly the head was fixated first, before any other ROI. Besides that it was also fixated more often, meaning that during scene presentation observers kept looking at the head. Consequently, no ROI was fixated longer in total then the head.
Additionally, also in line with @Zwickel2010 *referenced* objects were preferenced over the object not being *referenced* by the person in a given trial. The preference for the *referenced* object can be seen in several measures. First, the object which was *referenced* was fixated remarkably earlier. Furthermore, objects were also fixated longer with more frequent fixations when they were *referenced*. Therefore, the gaze cue by the person does not only leads to more thorough processing during the whole time of scene presentation, but also guides attentional resources very early. All these findings together indicate a strong prioritization through the gaze cue of the person in the scene.
<!-- saccacades -->
Moreover, the consistent prioritization of the head and the *referenced* object indirectly suggest a link between these two ROIs. To investigate a direct relation between these regions, leaving saccades from the head are examined as well. It is shown, that saccades leaving the head are more likely to end on the *referenced* object. This underlines a direct link between the head and the *referenced* object, and is again in line with @Zwickel2010. 
So far the given results replicate all aspects @Zwickel2010 demonstrated for persons in their study. However, this replication had considerably more power then the original study, used photographic scenes and included a top-down modulation. Although its unclear how the photographs changed the results compared to the computer rendered scenes, the higher power lead to more precise estimation of the effect sizes.
Note, however, that this was not a direct but a conceptual replication, showing that @Zwickel2010 findings can be generalized from computer rendered to photographic scenes.
<!-- top-down -->
  Besides replicating, this study aims also at extending the line of research, generalizing it to new stimuli and at testing the pattern in gaze behavior as it was shown here against top-down modulation, specifically an instructed task prior free-viewing. Unsurprisingly the task scores show, that observer, who knew about the free-recall task in advance perform better in recalling items. Furthermore, viewing behavior was different depending on group membership. Specifically, observer pay more attention to objects when they received the instruction prior to the viewing part, and at the same time the head loses some of its natural salience. Both findings are consistent over all measures. These findings suggest, that observers with instruction had a more systematic gaze pattern, where they preferred ROIs relevant to the task, namely the objects. However, no interaction between top-down modulation and ROI can be found. Consistently, social attention as well as joint attention remains for all measures stable. The prioritization shown for the head and also for the *referenced* object was unaffected by the given top-down modulation, although descriptive differences became smaller (note, that this trend was not significant). The attentional guidance of social and joint attentional processes can be seen, even when observers investigate the scene more systematic. This evidence provides support for the automaticity and reflexivness of the observed effects, even when the observer voluntarily aims at scanning the scene systematically. Nevertheless, observer with instructed free-recall task performed better. However, the contribution of the attentional reallocation remains unclear.
In particular, whether an object was cued or not by the person, did not influence its probability being recalled, but note that cued objects received more attention. That is partially inconsistent with the hypothesis, which stated correct that scene processing changes, but the actual link is missing that the change in processing for solving the task comes from the attentional reallocation of attention. Even as it is assumed, this findings do not indicate a link between spent attentional resources and performance for recall. This missing link can mean WHAT!? <!-- korrelation zeit angeschaut und erinnert? --> The results support previous findings that attention is shifted reflexively where other persons are looking at does not only hold for controlled laboratory settings [e.g. @Ristic2005,  @Hayward2017]. These evidence, which was previously extended to naturalistic scenes by [@Zwickel2010] is now tested against top-down modulation. Incrementally it is shown, that even when attentional allocation changes due to a more systematic viewing pattern, the shifts are still affected by gaze, as if the observers did pure free viewing.  <!-- Einordnen mit privious findings && unclear was bei anderen top down modulationen! -->
<!-- Conclusio -->
All in all, our results indicate that the mere presence of other human beings as well as their gaze orientation have a strong impact on attentional exploration. The observed attentional guidance of the gaze was so robust to resist even top-down modulation. It is concluded that attentional guidance by social attentional and joint attentional trigger is very robust.

#Schrott
Zwickel struktur: 1: general (social atteniton/head), 2: gaze cueing, 3(2a): diskutiert, 4(2b): diskutiert, 5: Leaving saccades, 6: head body, 7: surprising data, 8: vergleich mit unpassender studie, 9: conclusio
Meine struktur: 1: general (social attention/head) finding, 2: gaze cueing (object), 3: saccades (head -> object), 4: (kurzes oder detailliertes?!) fazit replication, 5: top down-modulation, 6: ?! DENK NACH! ?!, 7: conclusio



Unlike @Zwickel2010, naturalistic photographic are used, in contrast to computer rendered scenes.


<!-- was will ich erzählen?! --> Replikation --> Kopf-prio, gazed-prio, sac-prio! 
<!-- was ist relevant?! --> 
<!-- was überrascht nicht?! --> topdown-modulatioon verändert blickverhalten
<!-- was überrascht? --> Obwohl (!) top-down modulation, blickverhalten ändert, bleiben Effekte bestehen!



<!-- alt: 

For genuine social stimuli like the person, and more specifically the head and the body, a similar pattern can be observed. The head had the lowest latency until first fixation, so it is even shorter then the latency till first fixation for the *referenced* object. Under the light of joint attention this makes sense, since it is assumed, that the head in the first place leads the gaze of the observer to the *referenced* object. Additionally, the head was also fixated longer and more often then the body.

The extension of this line of research, namely whether the gaze behavior can be influenced by top-down modulation. Consequently, this research is extended by the given study by an explicit task concerning the given scene. this modulation has an impact on gaze behavior.

-->



\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
