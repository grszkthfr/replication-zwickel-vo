---
title             : "Presence of persons in naturalistic scenes and consequences - A conceptual replication"
shorttitle        : "Presence of persons in a naturalistic scene"

author:
  - name          : "Jonas Großekathöfer"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Marcusstraße 9-11, 97070 Würzburg"
    email         : "jonas.grossekathoefer@uni-wuerzburg.de"
  - name          : "Kristina Suchotzki"
    affiliation   : "1"
  - name          : "Matthias Gamer"
    affiliation   : "1"  

affiliation:
  - id            : "1"
    institution   : "Julius-Maximilian University, Würzburg"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.

keywords          : "keywords"
wordcount         : "?wordcountaddin"

bibliography      : 
  - "r-references.bib"
  - "../2017_repl-zwickel-vo.bib"

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            :
  papaja::apa6_pdf:
    keep_tex: TRUE
                      
---

```{r load_packages, include = FALSE}

library("papaja")
library("tidyverse")
library("car")
library("afex")
library("ggpubr")

```

```{r paths}

rm(list=ls())

pathMEM <- "../01_data/Memory/"
pathET <- "../01_data/prot/"
pathFB <- "../01_data/FB/"

```

```{r Generate prot}

```

```{r Check stimuli}

```

```{r Check baseline quality}

```

```{r Analyze fixations}

```

```{r Reading eye tracking data in, warning = FALSE, message = FALSE}

# ALL EYE TRACKING DATA
vpn <- paste0("vpja",ifelse(c(1:78,81:96)<10,"0",""),c(1:78,81:96))
bed <- rep(c("free","mem"),47)

# ORIGINALLY ACQUIRED DATA
#vpn <- paste0("vpja",ifelse(c(1:78)<10,"0",""),c(1:78))
#bed <- rep(c("free","mem"),39)

bed <- bed[!(vpn %in% "vpja23")]  # missing data
vpn <- vpn[!(vpn %in% "vpja23")]  

# Loop over subjects
erg <- numeric(); nvalid <- numeric(); cleantime <- numeric()
for (vp in vpn) {
  #  print(vp)

  prot <- read.csv2(paste0(pathET,vp,"_Fixations.csv"))

  # Restrict to trials with valid baseline?
  nvalid <- c(nvalid,sum(prot$blok==1))
  prot <- prot[prot$blok==1,]

  cleantime <- c(cleantime,mean(prot$cleantime))

  erg <- rbind(erg,apply(prot[,8:ncol(prot)],2,mean,na.rm=TRUE))
}

df.w.et <- data.frame(code=vpn,group=bed,nvalid,cleantime,erg)


df.l.et <- gather(df.w.et, key, value, fix.face:sac.bnongaze, factor_key=TRUE) %>%
  mutate(
    key = as.character(key),
    fixations =
      as.factor(
        ifelse(startsWith(key, "fix."), "fix",
             ifelse(startsWith(key, "fixn."), "fixn",
                    ifelse(startsWith(key, "fixlat."), "fixlat",
                           ifelse(startsWith(key, "sac."), "sac", NA))))),
    region =
      as.factor(
        ifelse(endsWith(key, ".face"), "face",
               ifelse(endsWith(key, ".body"), "body",
                      ifelse(endsWith(key, ".gaze"), "gaze",
                             ifelse(endsWith(key, ".nongaze"), "nongaze",
                                    ifelse(endsWith(key, ".pgaze"), "pgaze",
                                           ifelse(endsWith(key, ".fgaze"), "fgaze",
                                                  ifelse(endsWith(key, ".bgaze"), "bgaze",
                                                         ifelse(endsWith(key, ".pnongaze"), "pnongaze",
                                                                ifelse(endsWith(key, ".fnongaze"), "fnongaze",
                                                                       ifelse(endsWith(key, ".bnongaze"), "bnongaze",NA)))))))))))) %>%
  arrange(code)

rm(prot, bed, cleantime, nvalid, vp, vpn, erg)

```

```{r Reading memory data in, warning = FALSE, message = FALSE}

# ALL MEMORY DATA
vpn <- paste0("vpja",ifelse(c(1:78,81:96)<10,"0",""),c(1:78,81:96))
bed <- rep(c("free","mem"),47)

# ORIGINALLY ACQUIRED DATA
#vpn <- pasteo("vpja",ifelse(c(1:78)<10,"0",""),c(1:78))
#bed <- rep(c("free","mem"),39)

# Loop over subjects
erg <- numeric()
for (vp in vpn) {
  # print(vp)

  prot <- read.csv2(paste0(pathMEM,vp,".csv"))

  # Item recalled
  gaze <- sum(prot$memgazedat)
  nogaze <- sum(prot$memnongazedat)

  erg <- rbind(erg,c(gaze,nogaze))
}

df.w.mem <- data.frame(code=vpn,bed,erg)               
names(df.w.mem) <- c("code","bed","memgaze","memnogaze")

rm(gaze, nogaze, erg, prot, bed, vp, vpn)

```

```{r Reading questionnaire data in, warning = FALSE, message = FALSE}

df.w.demo <- read_csv2(paste0(pathFB,"Projektarbeit_Dateneingabemaske.csv")) %>%
  transmute(
    vp = as.factor(VP_Nr),
    sex = as.factor(Demo_Sex),
    age = Demo_Alter,
    aq_social = ifelse((5-AQK_1) < 3, 1, 0) + ifelse((5-AQK_7) < 3, 1, 0) + ifelse(AQK_8 < 3, 1, 0) + ifelse((5-AQK_10) < 3, 1, 0) + ifelse((5-AQK_11) < 3, 1, 0) + ifelse(AQK_13 < 3, 1, 0) + ifelse((5-AQK_14) < 3, 1, 0) + ifelse((5-AQK_20) < 3, 1, 0) + ifelse((5-AQK_24) < 3, 1, 0) + ifelse((5-AQK_28) < 3, 1, 0) + ifelse((5-AQK_31) < 3, 1, 0), # 5- 'item' for reversed items, then if 1/2 -> 1, 3/4 -> 0  
    aq_imagination = ifelse((5-AQK_3) < 3, 1, 0) + ifelse((5-AQK_5) < 3, 1, 0) + ifelse((5-AQK_6) < 3, 1, 0) + ifelse((5-AQK_9) < 3, 1, 0) + ifelse((5-AQK_16) < 3, 1, 0) + ifelse((5-AQK_17) < 3, 1, 0) + ifelse((5-AQK_18) < 3, 1, 0) + ifelse((5-AQK_22) < 3, 1, 0) + ifelse((5-AQK_23) < 3, 1, 0) + ifelse((5-AQK_26) < 3, 1, 0) + ifelse((5-AQK_32) < 3, 1, 0) + ifelse((5-AQK_33) < 3, 1, 0),
    aq_communication = ifelse(AQK_2 < 3, 1, 0) + ifelse(AQK_4 < 3, 1, 0) + ifelse(AQK_12 < 3, 1, 0) + ifelse(AQK_15 < 3, 1, 0) + ifelse(AQK_19 < 3, 1, 0) + ifelse(AQK_21 < 3, 1, 0) + ifelse(AQK_25 < 3, 1, 0) + ifelse(AQK_27 < 3, 1, 0) + ifelse(AQK_29 < 3, 1, 0) + ifelse(AQK_30 < 3, 1, 0),
    aq_sumscore = ifelse((5-AQK_1) < 3, 1, 0) + ifelse(AQK_2 < 3, 1, 0) + ifelse((5-AQK_3) < 3, 1, 0) + ifelse(AQK_4 < 3, 1, 0) + ifelse((5-AQK_5) < 3, 1, 0) + ifelse((5-AQK_6) < 3, 1, 0) + ifelse((5-AQK_7) < 3, 1, 0) + ifelse(AQK_8 < 3, 1, 0) + ifelse((5-AQK_9) < 3, 1, 0) + ifelse((5-AQK_10) < 3, 1, 0) + ifelse((5-AQK_11) < 3, 1, 0) + ifelse(AQK_12 < 3, 1, 0) + ifelse(AQK_13 < 3, 1, 0) + ifelse((5-AQK_14) < 3, 1, 0) + ifelse(AQK_15 < 3, 1, 0) + ifelse((5-AQK_16) < 3, 1, 0) + ifelse((5-AQK_17) < 3, 1, 0) + ifelse((5-AQK_18) < 3, 1, 0) + ifelse(AQK_19 < 3, 1, 0) + ifelse((5-AQK_20) < 3, 1, 0) + ifelse(AQK_21 < 3, 1, 0) + ifelse((5-AQK_22) < 3, 1, 0) + ifelse((5-AQK_23) < 3, 1, 0) + ifelse((5-AQK_24) < 3, 1, 0) + ifelse(AQK_25 < 3, 1, 0) + ifelse((5-AQK_26) < 3, 1, 0) + ifelse(AQK_27 < 3, 1, 0) + ifelse((5-AQK_28) < 3, 1, 0) + ifelse(AQK_29 < 3, 1, 0) + ifelse(AQK_30 < 3, 1, 0) + ifelse((5-AQK_31) < 3, 1, 0) + ifelse((5-AQK_32) < 3, 1, 0) + ifelse((5-AQK_33) < 3, 1, 0))

```

# Introduction
    <!-- kickoff -->
Humans in their social environment rely on the information other humans provide. This does not only holds for reading explicit signals, as in conversations, but also for implicit signals, as in gazes. Specifically, if an individual looks into a specific direction, this information is often read spontaneously and redirects the observers attention towards the referred object or location. The process of following someones gaze is called/can be referred to joint attention. These attentional shifts are crucial for joint attention. Laboratory studies showed, that joint attention can not only be induced by the gaze [for an detailed overview see: @Frischen2007a], but also from the body or the head itself [@Lawson2016].  
    <!-- gaze cuing to joint attenion & social attention -->
The most used paradigm to investigate these attentional shifts is the so called gaze-cueing paradigm [@Friesen1998; @Driver1999; @Langton2000]. These studies show that perceived gaze cues lead to a reflexive attentional shift, which results in an processing benefit for that location [for a very recent study see @Langton2017]. Even though gaze cues are crucial for joint attention, it is criticized that among others these studies used isolated heads [@Friesen1998; @Langton2000] or even cartoon heads [@Driver1999; @Ristic2005] as gaze cues, and therefore lack ecological validity [for an overview on ecological validity see: @Risko2012]. For example, in an recent study @Hayward2017 did not find reliable links between classical laboratory gaze cueing tasks and a real social engage.  
The relevance/sensibility/focus to ecologically valid stimuli is a core aspect of social attention research, which provides an bigger framework for gaze cueing [@Itier2009]. The research describes attentional consequences of social interactions and focuses often on similarities and differences of different types of social stimuli [@Risko2012]. The types range from real human interactions [for example: @Laidlaw2011, @Freeth2013a] to highly controlled laboratory settings with isolated faces as stimuli [for example: @Langton2017]. The main finding of this research line is, that some research findings related to social stimuli do not extend to the real world and researches must be sensible to these differences when generalizing laboratory findings [@Jarick2015; @Hayward2017; for an overview see: @Risko2016].  
    <!-- social attention -->
<!--Birmingham2008 und Birmingham2009b als vormacher und grundsätzliche Idee das problem anzugehen, weitere Ansätze-->To account for the ecological validity of gaze cues @Zwickel2010 conducted a joint attention study with a more naturalistic scenario. First of all, in their study participants had no explicit task to fulfill. @Zwickel2010 argue, that the lack of a specific task results in more naturalistic viewing behavior and therefore adds more ecological validity to the classical gaze cuing paradigms. In this so called free-viewing paradigm they presented their observers multiple scenes for several seconds. The scenes contained a reference, either a person or a loudspeaker, and two objects. One of the objects was referenced either by an oriented person or loudspeaker. They showed that observers spontaneously prioritize the referenced object, but only when it was referenced by the person. The attentional focus of the person in the scene did influence the attentional distribution of the observer. Interestingly, the same was not true for the loudspeaker. So the referenced objects were not just focused because they might have been salient by themselves, but became more salient merely by the persons reference. <!--detailierter?!--> This finding is in line with predictions by the social attention. First, that social stimuli are prioritized was confirmed by the results, the most prioritized region was still the head of the shown person.Additionally, with regard to joint attention, the referenced object was fixated remarkably earlier, more often and overall longer then the not referenced object. After all, @Zwickel2010 provide evidence that joint attention as consequence of the gaze cue happens spontaneously and that it has high relevance in naturalistic situations.<!--softerer übergang pls-->
    <!-- research motivation -->
However, this conceptual replication of @Zwickel2010 aims at answering multiple research questions regarding joint and social attention, including the replication of Zwickel and Võ's [-@Zwickel2010] findings and extending this line of research.  
@Zwickel2010 had very little power in their study, with n = 16 participants<!-- zu unserer Power was schreiben?!-->. Additionally they used computer generated stimuli in contrast to their motivation to provide a naturalistic setup. Here, more naturalistic stimuli and a bigger sample size is used. Specifically, for more naturalistic stimuli real photographs are chosen over computer rendered scenes. As often, by being more naturalistic experimental control is reduced. The consequences are hold to a minimum by producing the stimuli the same way <!--genauer, klammer auflösen--> (each scene four times, with the individual looking twice to the left and right to each object). Nevertheless, in real photographs small changes are unavoidable. Whereas @Zwickel2010 only rotate the figure in the computer rendered scene, they have complete control of all the changes, e.g. angel of the body, facial expression. Here, another photography was taken. As consequence, for example, the body orientation within the four balanced scenes can not be perfectly controlled and might differ slightly between photographs within scenes.<!-- nochmal sagen, warum das torztdem toll ist? --> With higher power and more naturalistic stimuli this study will still<!-- still, however, nevertheless, yet, regardless, even though, despite --> underline @Zwickel2010 findings and tackle the two mentioned flaws. However, in this study we presume that the effect showed by @Zwickel2010 is genuine for social stimuli, therefore there is no non-social condition comparable to the loudspeaker-condition.  
    <!-- extended research -->
In fact, this line of research is being extended. First, the influence of top-down modulations on joint and social attention in naturalistic scenes is investigated. Earlier research showed, that social attention is influenced by multiple factors. For example, social status [@Foulsham2010] or expectations [@Perez-Osorio2015] change the viewing behavior of the observer. These studies have in common that they often manipulate the observers implicitly.  
This is in contrast to the present study, where a very <!-- for one group-->explicit manipulation is used for half of the observers. Additionally, consequences for latter cognitive processes, here memory effects, are examined. Therefore one half of the observers received the information that a memory test is following before the experimental part started. This top-down modulation is thought to induce a more explicit and systematic encoding of the presented scenes. The other half of the observers did not receive any top-down modulation, just like @Zwickel2010, but did the memory task unannounced after the experimental part. For both groups the memory task was a free-recall test where they had to recall as many as things as possible from the scenes.  <!-- Top-Down Modulation findings??? -->
As @Zwickel2010 showed, a person in a scene influences the viewing behavior of observers spontaneously and without further instruction or manipulation. Here the given instruction to complete a memory test was thought to influence the viewing behavior, in that sense, that spontaneous viewing behavior will be reduced. It is important to note, that it is not expected that the influence of the presence of the person would vanish due to top-down modulation, but it is supposed to be weaker. Effects should be visible regardless for the social attention part and also for the joint attention part of this study.  
    <!-- Hypothesis -->
<!-- alter baustein: First, for joint attention, it is presumed to replicate the main effects of a persons presence on the observer described by @Zwickel2010. It is therefore hypothesized that the gaze of the person in the scene leads to prioritization for the gazed-at/referenced object. The prioritization can be seen in earlier, more and longer fixations. In line with @Zwickel2010 it is also expected, that saccades leaving from the head are more likely to move to the gazed-at object. -->
        <!-- joint attention/gaze following -->
The foundation/base/idea/motivation of/for this study is to replicate the findings by [@Zwickel2010].  
*H1*. Consequently, a prioritization for the gazed-at objects is predicted. In line with @Zwickel2010, this  prioritization can be measured in multiple ways. First there should be an early fixation bias towards the gazed-at object. During presentation time, the total time that the gazed-at object is fixated should be prolonged, with more fixations as well. For saccades it is expected, that leaving from the head it is more likely to move to the gazed-at object, in contrast to the not-gazed-at object.<!--Main effect icond, Anova-->  
*H2*. New, compared to Zwickel and Võ's [-@Zwickel2010] study, is the instruction condition. For gaze-following it is expected that the exclusive prioritization for the gazed-at object will decrease for subjects in explicit-encoding group, due to the instruction of the memory test and a more explicit and systematic processing of the scene. This means smaller differences in the fixation measurements are expected. For leaving saccades it is also expected that the under H1n stated effect decreases. <!--1st: (Interaction group:icond)
(?!Hypothese zu Gruppen, dass explicit mehr focus auf Gegensätnde richtet, da anweisung? (Maineffect group) -->  
*H3*. Also new is the follow-up memory test for the two potentially gazed-at objects. First it is assumed, that subjects with announced memory test will recall more items, because they process the scenes more thorough. Additionally it is expected, that in the free-recall condition gazed-at objects are better recalled then not-gazed at objects.
        <!-- social attention -->
*H4*. As naturalistic scenes are used, the basic effects of social attention are expected. This means, that the head will be prioritized over the body. This prioritization can be measured, in multiple ways. And again, it is expected, that first fixation fell earlier on the head, that it is fixated longer and more often then the body. Additionally, fixations occur earlier on the head, then on the gazed-at object, because the gaze-cue needs to be processed in advance.<!--gibt's gar keine Analyse für!!!-->  
*H5*. Due to the instruction of the memory test, and the assumed change in processing the scene, the viewing behavior should change for social stimuli. Due to explicit encoding, it is expected that natural viewing behavior which is know to prioritize the head is reduced and therefore the head looses some of its salience. As a consequence, the head should be prioritized stronger in the free-viewing group compared to the explicit-encoding group. Resulting in longer fixations, faster fixations and more fixations. 

# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants
In this study `r length(df.w.demo$vp)` observers (`r length(df.w.demo$sex[df.w.demo$sex==1])` female and `r length(df.w.demo$sex[df.w.demo$sex!=1])` male) between `r min(df.w.demo$age)` and `r max(df.w.demo$age)` years (M = `r round(mean(df.w.demo$age),2)`, SD = `r round(sd(df.w.demo$age),2)`) participated voluntarily. All observer had normal or corrected vision and were recruited at the University of Würzburgs online subject pool or by blackboard. For participation observers received study credit or 5€. One observer was excluded due to missing data.

## Stimuli and Apparatus
The experimental stimuli consisted 26 different scenes with a single individual in the center looking at one of two objects of interests in the right or left half of the photography. The direction of the gaze cue and the place of the objects were balanced, creating 104 unique naturalistic scenes in the end. For each participant, a set was randomly generated from this pool containing each scene only once, resulting in 26 trials with exclusive scenes. Eye movements were recorded with an EyeLink1000
tower system, sampling at 1000 Hz.

## Design & Procedure
A two-level (instruction: free viewing/ explicit encoding) between subjects factor and a two-level (reference: cued/uncued) within subjects factor was manipulated in the experiment. After giving full informed consent, the eye-tracker was calibrated for each observer. Observers were then told either that there is a follow-up memory test or nothing. The presentation of the stimuli was randomized. In each trial the scene was present for 10 seconds. Observers were told to look at the scene as they would look at photographs. Inter trial interval was randomized between 2 and 4 seconds. After the last trial participants filled in questionnaires (demographics, autism-questionnaire (short), and Inventar soziale kompetenz) and were asked to recall as many items as possible in a free recall memory-test. Afterwards participants received their credit.


## Data analysis
Regions-of-Interest were hand-drawn around the relevant objects and the face and body of the individual in the center. These ROIs were color-coded for cued and uncued objects and also for the head and body of the individual on the photography to determine gaze locations. Outlier detection.

`r cite_r("r-references.bib")` is used for all analyses.


# Results
Prioritization of the ROIs in the scene were measured in multiple ways. 

## Joint attention/ gaze following

As a measure of prioritization fixation duration, fixation number, fixation latency, as well as leaving saccades are used.

### Fixations
```{r TO-DO: Plots fixations joint, warining = FALSE, message = FALSE}

```

```{r Descriptives fix*, warining = FALSE, message = FALSE}

# Descriptives for fixation chacracteristics for joint attention

dscr.fix.rpl <- df.w.et %>%
  group_by(group) %>%
  summarise_at(vars(fix.face:fixlat.nongaze), funs(mean,sd,se=sd(.)/sqrt(n()))) %>% # mit den funs() die variablen vars(von:bis) berechnen
  gather(key, measure, fix.face_mean:fixlat.nongaze_se) %>% # ins longformat
  mutate(fix = as.factor(map(strsplit(key,"[[:punct:]]"), ~.x[1]) %>% unlist()),
         gazed = map(strsplit(key,"[[:punct:]]"), ~.x[2]) %>% unlist(),
         gazed = as.factor(substring(gazed,1)),
         stat = as.factor(map(strsplit(key,"[[:punct:]]"), ~.x[3]) %>% unlist()),
         key = as.factor("replication")) %>% # 
  select(-measure, everything()) %>% # neusortieren der variablen
  select(key, everything())

dscr.fix.rpl$gazed <- factor(dscr.fix.rpl$gazed, levels=c("face", "body", "gaze", "nongaze"))

dscr.fix.zwckl <- data.frame(group="free",fix=c("fix","fix","fix","fix","fixn","fixn","fixn","fixn","fixlat","fixlat","fixlat","fixlat"), gazed=c("gaze","gaze", "nongaze", "nongaze"), stat=c("mean","se"), measure=c(0.08,.01,.07,.01,5.89,.37,5.24,.34,3588,133,4008,166)) # free = person

```

```{r Anova fixations joint, warning = FALSE, message = FALSE}

# ANOVA Fixations characteristics for joint attention
## 2 (Group) x 2 (Gaze) ANOVA

icond <- gl(2,1,labels=c("cued","uncued")) # within-factor
idata <- data.frame(icond)

for (st in seq(7,16,4)) { # Variables 7:16, every 4th: fix.gaze and fix.nogaze; fixn.gaze and ...
  carmod <- lm(as.matrix(df.w.et[,st:(st+1)]) ~ df.w.et$group)
  #print(colnames(df.w.et[,st:(st+1)]))
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }

rm(carmod, idata, icond, st)

```

#### Fixation duration
<!-- (H1, H2) -->
To quantify and compare prioritization against each object a measure on how big the proportion of the duration of all fixations was for every ROI was calculated. Specifically, the time duration on an object was divided by <!-- The relative cumulative fixation duration is calculated as time duration on an object divided by--> the time spent fixating the rest of the scene to get a  was for  fixated relative to all fixations.<!-- what do you get then!? -->  It shows a bias towards the gazed-at object, which was fixated longer (see Table/Figure) and confirms [@Zwickel2010]'s findings. As predicted the corresponding ANOVA revealed a significant main effect for reference, `r apa.anova.fix.gaze$full_result$icond` and for condition `r apa.anova.fix.gaze$full_result$df_w_et_group`. Against prediction their was no effect of the two-way interaction, `r apa.anova.fix.gaze$full_result$df_w_et_group_icond`. <!-- was it against pred? --> 


#### Fixation latency
<!-- (H1, H2) -->
An additional measurement of prioritization is fixation latency, that is for each OOI the mean out of all first fixations after stimulus onset <!--besser formulieren!!-->. In line with [@Zwickel2010], an object is fixated earlier when it is gazed-at. But also when the observer was in the explicit encoding condition. The statistical significance is confirmed by an ANOVA: for reference `r apa.anova.fixlat.gaze$full_result$icond` and condition, `r apa.anova.fixlat.gaze$full_result$df_w_et_group`). For fixation latency with a trend(?) for an interaction, `r apa.anova.fixlat.gaze$full_result$df_w_et_group_icond`.

#### Fixation number
<!-- (H1, H2) -->
As a third measurement of prioritization, fixation number, as the count of fixations per ROI during scene presentation, divided by the total number of fixations during scene presentation, was calculated. It shows, that OOI were fixated more often when gazed-at `r apa.anova.fixn.gaze$full_result$icond`, again in line with [@Zwickel2010]. Objects were also more often fixated in the explicit encoding condition`r apa.anova.fixn.gaze$full_result$df_w_mem`, and again against prediction there was no interaction, `r apa.anova.fixn.gaze$full_result$df_w_et_group_icond`.
 

### Saccades

```{r descriptives saccade, include=FALSE}
dscr.sac.rpl <- df.w.et %>%
  group_by(group) %>%
  summarise_at(vars(sac.pgaze:sac.bnongaze), funs(mean,sd,se=sd(.)/sqrt(n()))) %>% # mit den funs() die variablen vars(von:bis) berechnen
  gather(key, measure, sac.pgaze_mean:sac.bnongaze_se) %>% # ins longformat
  mutate(stat = as.factor(map(strsplit(key,"[[:punct:]]"), ~.x[3]) %>% unlist()),
         area = map(strsplit(key,"[[:punct:]]"), ~.x[2]) %>% unlist(),
         area = as.factor(substring(area,1,1)),
         gazed = map(strsplit(key,"[[:punct:]]"), ~.x[2]) %>% unlist(),
         gazed = as.factor(substring(gazed,2)), 
         key = as.factor("replication")) %>% #rausnehmen, zur kontrolle, ob alles passt, was oben läuft.
  select(-measure, everything()) %>% # neusortieren der variablen
  select(key, everything())

dscr.sac.zwckl <- data.frame(key=c("zwickel","zwickel"),group=c("free", "free"),gazed=c("gaze", "gaze", "nongaze", "nongaze"),stat=c("mean", "se"),measure=c(.14,0.01,.09,0.01)) # free = person

```

```{r Matthias plots saccade, include=FALSE, echo = FALSE}
# Plots: Saccade data
'
farben <- c("blue","yellow")
ttxt <- c("Person","Face","Body")

for (i in 1:3) {
  st <- (17:19)[i]

  # Fixation density
  m  <- cbind(apply(df.w.et[df.w.et$group=="free",c(st,st+3)],2,mean),
              apply(df.w.et[df.w.et$group=="mem",c(st,st+3)],2,mean))
  se <- cbind(apply(df.w.et[df.w.et$group=="free",c(st,st+3)],2,sd)/sqrt(sum(df.w.et$group=="free")),
              apply(df.w.et[df.w.et$group=="mem",c(st,st+3)],2,sd)/sqrt(sum(df.w.et$group=="mem")))

  yrng <- c(0,max(m+se))

  x <- barplot(m,beside=TRUE,col=farben,ylim=yrng,xlab="",ylab="% of total fixation time")
  arrows(x,m-se,x,m+se,length=0.03,angle=90,code=3,col="black")
  axis(1,apply(x,2,mean),c("Free viewing","Explicit encoding"),tick=FALSE)

  title(ttxt[i])
}

legend(max(x),max(yrng),c("Cued","Uncued"),fill=farben,xjust=1,yjust=1)

rm(m, se, yrng, x, st, farben, ttxt, i)
'
```

```{r Anova saccades, warning=FALSE, message=FALSE}
# ANOVA Saccades
## 2 (Group) x 2 (Gaze) ANOVA

icond <- gl(2,1,labels=c("cued","uncued")) # within-factor
idata <- data.frame(icond)

for (st in 17:19) {
  carmod <- lm(as.matrix(df.w.et[,c(st,(st+3))]) ~ df.w.et$group)
  #print(colnames(df.w.et[,c(st,(st+3))]))
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }



rm(carmod, idata, icond, st)
```

#### Leaving saccades
<!-- (H1, H2) -->
The second hypothesis predicts, that there are more saccades leaving from the head to the gazed-at object. Furthermore it is claimed, that an interaction between instruction and reference results in increasing differences in the free-viewing condition. An Anova supports the first claim. There is an significant main effect for reference, `r apa.anova.sac.fgaze$full_result$icond`, and also for group,  `r apa.anova.sac.fgaze$full_result$df_w_et_group`. No confirmation was found for the predicted interaction between reference and instruction `r apa.anova.sac.fgaze$full_result$df_w_et_group_icond`.

### Memory
<!-- (H3) -->

```{r plots memory}

```

```{r Anova memory, warning=FALSE, message=FALSE, echo = FALSE}
# Recalled items
# 2 (Condition) x 2 (Gaze) ANOVA (auf erinnerte Details)

imem <- gl(2,1,labels=c("cued","uncued"))
idata <- data.frame(imem)

# Car
carmod <- lm(as.matrix(df.w.mem[,3:4]) ~ df.w.mem$bed)
# print(colnames(df.w.mem[c(3,4)]))
#print(Anova(carmod, idata=idata, idesign=~imem, type="III"))
anova.mem <- Anova(carmod, idata=idata, idesign=~imem, type="III")
apa.anova.mem <- apa_print(Anova(carmod, idata=idata, idesign=~imem, type="III"), correction="GG", mse = FALSE)

dscr.mem <- df.w.mem %>% summarise(mean(memgaze), sd(memgaze), mean(memnogaze), sd(memnogaze))
dscr.mem.group <- df.w.mem %>% group_by(bed) %>% summarise(mean(memgaze), sd(memgaze), mean(memnogaze), sd(memnogaze))

rm(imem, idata, carmod)
```
The free-recall test showed, that unsurprisingly observers with explicit encoding remembered on average 2 items more then observers from the other group. An Anova proved this effect as statistically significant, `r apa.anova.mem$full_result$df_w_mem_bed`. Referencing an OOI did not influence memory performance, `r apa.anova.mem$full_result$imem`. There was also no interaction, `r apa.anova.mem$full_result$df_w_mem_bed_imem`.
The free recall-memory test was applied successful. Observers with instruction performed better in terms of recalling objects from the scenes.

## Social attention
A similar pattern to the OOI can be seen when comparing the head with the body region. Again there were the same measurements to account for prioritization. 

```{r TO-DO: Plots fixations social, warining = FALSE, message = FALSE}

```

```{r Descriptives fixations social, warining = FALSE, message = FALSE}

# Descriptives for fixation chacracteristics for social attention

dscr.fixsoc <- df.w.et %>% summarise(mean(fix.face), sd(fix.face), mean(fix.body), sd(fix.body), mean(fixn.face), sd(fixn.face), mean(fixn.body), sd(fixn.body), mean(fixlat.face), sd(fixlat.face), mean(fixlat.body), sd(fixlat.body))
dscr.fixsoc.group <- df.w.et %>% group_by(group) %>% summarise(mean(fix.face), sd(fix.face), mean(fix.body), sd(fix.body), mean(fixn.face), sd(fixn.face), mean(fixn.body), sd(fixn.body), mean(fixlat.face), sd(fixlat.face), mean(fixlat.body), sd(fixlat.body))
```

```{r Anova fixations social, warning = FALSE, message = FALSE}
# ANOVA Fixations characteristics
## 2 (Group) x 2 (Face/Body) ANOVA

icond <- gl(2,1,labels=c("head","body")) # within-factor
idata <- data.frame(icond)

for (st in seq(5,16,4)) { # Variables 5:16, every 4th: fix.face and fix.noface; fixn.face and ...
    carmod <- lm(as.matrix(df.w.et[,st:(st+1)]) ~ df.w.et$group)
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }


rm(carmod, idata, icond, st)

```
Analysis for the social attention part contained again Anovas for the different dependent variables indicating prioritization.

### Face vs body fixation (H4)
The first measurement shows, that faces were fixated longer then the body  (Table X), `r apa.anova.fix.face$full_result$icond`, but there is no difference between the instruction-groups, `r apa.anova.fix.face$full_result$df_w_et_group`, and no interaction (trend) between the two factors, `r apa.anova.fix.face$full_result$df_w_et_group_icond`.
The same pattern can be seen for fixation number, where there is a strong effect for region, with more fixations on the face, `r apa.anova.fixn.face$full_result$icond` and no difference between the instructions, `r apa.anova.fixn.face$full_result$df_w_et_group`, and no interaction `r apa.anova.fixn.face$full_result$df_w_et_group_icond`.
Latencies of fixation differed also remarkably between head and body, but only for region `r apa.anova.fixlat.face$full_result$icond`. There was neither an effect for instruction, `r apa.anova.fixlat.face$full_result$df_w_et_group` nor was their an interaction, `r apa.anova.fixlat.face$full_result$df_w_et_group_icond`.

### Free-viewing vs explicit-encoding face fixations (H5)
```{r Plots free vs mem face fixations, warning = FALSE, message = FALSE}

# plots

plot.face.free_vs_mem <- df.l.et %>%
  filter(fixations=="fix" & region=="face") %>%
  ggboxplot(x = "fixations", y = "value",
                fill = "group", palette =c("#00AFBB", "#E7B800", "#FC4E07"),
                add = "jitter", shape = "group") #+
  #stat_compare_means()
plot.face.free_vs_mem

```

```{r T-test face fixations, warning = FALSE, message = FALSE}

# Fixations Face in Free Viewing vs. Explicit Encoding

for (st in seq(5,16,4)) {
  msd <- c(mean(df.w.et[df.w.et$group=="free",st]),sd(df.w.et[df.w.et$group=="free",st]),
           mean(df.w.et[df.w.et$group=="mem",st]),sd(df.w.et[df.w.et$group=="mem",st]))
  teststat <- t.test(df.w.et[,st] ~ df.w.et$group)
  
  assign(paste0("ttest.",colnames(df.w.et)[st]), data.frame(M.free=msd[1],SD.free=msd[2], M.mem=msd[3], SD.mem=msd[4],  df=teststat$parameter, t=teststat$statistic, p=teststat$p.value))
 
  assign(paste0("apa.ttest.",colnames(df.w.et)[st]), apa_print(t.test(df.w.et[,st] ~ df.w.et$group)))
  }


rm(msd, teststat, st) 

```

A t-test between face fixation for the different groups provides information whether faces are differently processed dependent on the instruction observers get. Only fixation latency differed significantly between groups, `r apa.ttest.fixlat.face$full_result`, with faster fixations for the free viewing group. For fixation duration there was only a trend for difference between groups, `r apa.ttest.fix.face$full_result`. And fixation number did not differ, `r apa.ttest.fixn.face$full_result`.   

# Discussion

<!-- Main motivation -->
The main attempt of this study was to replicate attentional prioritization from the mere presence of a person in a scene on gaze behavior, what was first shown by @Zwickel2010. Unlike @Zwickel2010, naturalistic photographic are used, in contrast to computer rendered scenes.
<!-- Replikation -->
Nevertheless, the findings in this study match findings from @Zwickel2010. As @Zwickel2010 and others (for example @Birmingham2008) show, a strong prioritization can be seen for heads in the naturalistic scenes. Accordingly the head had was fixated first compared with all ROIs. Besides that it was also fixated more often, so that during the time observers kept looking at the head. Overall it was fixated the longest.
And in line with @Zwickel2010 there was also a strong prioritization for the object that was gazed at by the present person compared to the object that was not gazed-at in a given trial. This strong preference for the gazed-at object can be seen in several measures. First, first fixation for the object which was gazed-at were earlier, compared to the not gazed-at object. Furthermore, the gazed-at objects were also longer fixated and also more frequent fixated. Therefore, the gazed-at objects were not only processed more thoroughly during the whole time of scene presentation, but also bind attentional resources very early.
If the head... then ... . To examine these dependencies between the head region of the present person and the gazed-at object saccades leaving the head were looked at. Saccades leaving the head were more <!-- schon wäre auch die Aussage MOST likley--> likely to end on the gaze-at object, compared to the not-gazed-at-object.
<!-- replication effort: success! -->
These results replicate, what @Zwickel2010 already demonstrated in their study. However, in this experiment the effect sizes are, overall, bigger with smaller standard errors.

Note, however, that this was not a direct replication but a conceptual, showing that @Zwickel2010 findings can be generalized from computer render scene to photographic scenes.
<!-- erweiterung topdown -->
However, a direct replication was not the only motivation for this experiment. It aims also at testing the pattern in gaze behavior as it was shown here and in @Zwickel2010 against a specific top-down modulation. Together with the better performance in the free-recall task, viewing behavior changed from observers in the explicit encoding groups. Specifically, objects gain more attention in contrast to the free-viewing condition. Additionally, the head loses some of its natural salience, consistent for all measures. It can be concluded, observers with instruction had a more systematic gaze pattern, so that they take account for succeeding in the instructed task. Interestingly, however, top-down-modulation does not interact with either social attention nor joint attention consistent for all measures. The prioritization shown for the head and also for the gazed-at object remain stable, unaffected of this specific top-down modulation. The influence of social and joint attention is can be seen, even when observers investigate the scene more systematic. This evidence provides support how automatic and reflexive the observed effects are. Furthermore, they can not be easily overwritten.<!-- Einordnen mit privious findings && unclear was bei anderen top down modulationen! -->

All in all, it is concluded that without a specific task, and even with a task that makes the person in the scene irrelevant, the observers gaze behavior is influenced by the presence of a person in a scene. The task was not enough manipulation to kill the joint attention effects of social attention effects.  

<!-- Conclusio -->
Zwickel struktur: 1: general (social atteniton/head), 2: gaze cueing, 3(2a): diskutiert, 4(2b): diskutiert, 5: Leavin saccades, 6: head body, 7: surprising data, 8: vergleich mit unpassender studie, 9: conclusio
Meine struktur: 1: general (social attention/head) finding, 2: gaze cueing (object), 3: saccades (head -> object), 4: (kurzes oder detailliertes?!) fazit replication, 5: top down-modulation, 6: ?! DENK NACH! ?!, 7: conclusio

<!-- was will ich erzählen?! --> Replikation --> Kopf-prio, gazed-prio, sac-prio! 
<!-- was ist relevant?! --> 
<!-- was überrascht nicht?! --> topdown-modulatioon verändert blickverhalten
<!-- was überrascht? --> Obwohl (!) top-down modulation, blickverhalten ändert, bleiben Effekte bestehen!



<!-- alt: 

For genuine social stimuli like the person, and more specifically the head and the body, a similar pattern can be observed. The head had the lowest latency until first fixation, so it is even shorter then the latency till first fixation for the gazed-at object. Under the light of joint attention this makes sense, since it is assumed, that the head in the first place leads the gaze of the observer to the gazed-at object. Additionally, the head was also fixated longer and more often then the body.

The extension of this line of research, namely whether the gaze behavior can be influenced by top-down modulation. Consequently, this research is extended by the given study by an explicit task concerning the given scene. this modulation has an impact on gaze behavior.


-->



\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
