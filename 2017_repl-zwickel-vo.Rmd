---
title             : "Presence of persons in naturalistic scenes and consequences - A conceptual replication"
shorttitle        : "Presence of persons in a naturalistic scene"

author:
  - name          : "Jonas Großekathöfer"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Marcusstraße 9-11, 97070 Würzburg"
    email         : "jonas.grossekathoefer@uni-wuerzburg.de"
  - name          : "Kristina Suchotzki"
    affiliation   : "1"
  - name          : "Matthias Gamer"
    affiliation   : "1"  

affiliation:
  - id            : "1"
    institution   : "Julius-Maximilian University, Würzburg"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.

keywords          : "keywords"
wordcount         : "?wordcountaddin"

bibliography      : 
  - "r-references.bib"
  - "2017_repl-zwickel-vo.bib"

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes

lang              : "english"
class             : "man"
output            :
  papaja::apa6_word:
    #keep_tex: FALSE
                      
---

```{r load_packages, include = FALSE}

library("papaja")
library("tidyverse")
library("car")
library("afex")
library("ggpubr")

```

```{r paths}

rm(list=ls())

pathMEM <- "data/Memory/"
pathET <- "data/prot/"
pathFB <- "data/FB/"

```

```{r Reading eye tracking data in, warning = FALSE, message = FALSE}

# ALL EYE TRACKING DATA
vpn <- paste0("vpja",ifelse(c(1:78,81:96)<10,"0",""),c(1:78,81:96))
bed <- rep(c("free","mem"),47)

# ORIGINALLY ACQUIRED DATA
#vpn <- paste0("vpja",ifelse(c(1:78)<10,"0",""),c(1:78))
#bed <- rep(c("free","mem"),39)

bed <- bed[!(vpn %in% "vpja23")]  # missing data
vpn <- vpn[!(vpn %in% "vpja23")]  

# Loop over subjects
erg <- numeric(); nvalid <- numeric(); cleantime <- numeric()
for (vp in vpn) {
  #  print(vp)

  prot <- read.csv2(paste0(pathET,vp,"_Fixations.csv"))

  # Restrict to trials with valid baseline?
  nvalid <- c(nvalid,sum(prot$blok==1))
  prot <- prot[prot$blok==1,]

  cleantime <- c(cleantime,mean(prot$cleantime))

  erg <- rbind(erg,apply(prot[,8:ncol(prot)],2,mean,na.rm=TRUE))
}

df.w.et <- data.frame(code=vpn,group=bed,nvalid,cleantime,erg)


df.l.et <- gather(df.w.et, key, value, fix.face:sac.bnongaze, factor_key=TRUE) %>%
  mutate(
    key = as.character(key),
    fixations =
      as.factor(
        ifelse(startsWith(key, "fix."), "fix",
             ifelse(startsWith(key, "fixn."), "fixn",
                    ifelse(startsWith(key, "fixlat."), "fixlat",
                           ifelse(startsWith(key, "sac."), "sac", NA))))),
    region =
      as.factor(
        ifelse(endsWith(key, ".face"), "face",
               ifelse(endsWith(key, ".body"), "body",
                      ifelse(endsWith(key, ".gaze"), "gaze",
                             ifelse(endsWith(key, ".nongaze"), "nongaze",
                                    ifelse(endsWith(key, ".pgaze"), "pgaze",
                                           ifelse(endsWith(key, ".fgaze"), "fgaze",
                                                  ifelse(endsWith(key, ".bgaze"), "bgaze",
                                                         ifelse(endsWith(key, ".pnongaze"), "pnongaze",
                                                                ifelse(endsWith(key, ".fnongaze"), "fnongaze",
                                                                       ifelse(endsWith(key, ".bnongaze"), "bnongaze",NA)))))))))))) %>%
  arrange(code)

rm(prot, bed, cleantime, nvalid, vp, vpn, erg)

```

```{r Reading memory data in, warning = FALSE, message = FALSE}

# ALL MEMORY DATA
vpn <- paste0("vpja",ifelse(c(1:78,81:96)<10,"0",""),c(1:78,81:96))
bed <- rep(c("free","mem"),47)

# ORIGINALLY ACQUIRED DATA
#vpn <- pasteo("vpja",ifelse(c(1:78)<10,"0",""),c(1:78))
#bed <- rep(c("free","mem"),39)

# Loop over subjects
erg <- numeric()
for (vp in vpn) {
  # print(vp)

  prot <- read.csv2(paste0(pathMEM,vp,".csv"))

  # Item recalled
  gaze <- sum(prot$memgazedat)
  nogaze <- sum(prot$memnongazedat)

  erg <- rbind(erg,c(gaze,nogaze))
}

df.w.mem <- data.frame(code=vpn,bed,erg)               
names(df.w.mem) <- c("code","bed","memgaze","memnogaze")

rm(gaze, nogaze, erg, prot, bed, vp, vpn)

```

```{r Reading questionnaire data in, warning = FALSE, message = FALSE}

df.w.demo <- read_csv2(paste0(pathFB,"Projektarbeit_Dateneingabemaske.csv")) %>%
  transmute(
    vp = as.factor(VP_Nr),
    sex = as.factor(Demo_Sex),
    age = Demo_Alter,
    aq_social = ifelse((5-AQK_1) < 3, 1, 0) + ifelse((5-AQK_7) < 3, 1, 0) + ifelse(AQK_8 < 3, 1, 0) + ifelse((5-AQK_10) < 3, 1, 0) + ifelse((5-AQK_11) < 3, 1, 0) + ifelse(AQK_13 < 3, 1, 0) + ifelse((5-AQK_14) < 3, 1, 0) + ifelse((5-AQK_20) < 3, 1, 0) + ifelse((5-AQK_24) < 3, 1, 0) + ifelse((5-AQK_28) < 3, 1, 0) + ifelse((5-AQK_31) < 3, 1, 0), # 5- 'item' for reversed items, then if 1/2 -> 1, 3/4 -> 0  
    aq_imagination = ifelse((5-AQK_3) < 3, 1, 0) + ifelse((5-AQK_5) < 3, 1, 0) + ifelse((5-AQK_6) < 3, 1, 0) + ifelse((5-AQK_9) < 3, 1, 0) + ifelse((5-AQK_16) < 3, 1, 0) + ifelse((5-AQK_17) < 3, 1, 0) + ifelse((5-AQK_18) < 3, 1, 0) + ifelse((5-AQK_22) < 3, 1, 0) + ifelse((5-AQK_23) < 3, 1, 0) + ifelse((5-AQK_26) < 3, 1, 0) + ifelse((5-AQK_32) < 3, 1, 0) + ifelse((5-AQK_33) < 3, 1, 0),
    aq_communication = ifelse(AQK_2 < 3, 1, 0) + ifelse(AQK_4 < 3, 1, 0) + ifelse(AQK_12 < 3, 1, 0) + ifelse(AQK_15 < 3, 1, 0) + ifelse(AQK_19 < 3, 1, 0) + ifelse(AQK_21 < 3, 1, 0) + ifelse(AQK_25 < 3, 1, 0) + ifelse(AQK_27 < 3, 1, 0) + ifelse(AQK_29 < 3, 1, 0) + ifelse(AQK_30 < 3, 1, 0),
    aq_sumscore = ifelse((5-AQK_1) < 3, 1, 0) + ifelse(AQK_2 < 3, 1, 0) + ifelse((5-AQK_3) < 3, 1, 0) + ifelse(AQK_4 < 3, 1, 0) + ifelse((5-AQK_5) < 3, 1, 0) + ifelse((5-AQK_6) < 3, 1, 0) + ifelse((5-AQK_7) < 3, 1, 0) + ifelse(AQK_8 < 3, 1, 0) + ifelse((5-AQK_9) < 3, 1, 0) + ifelse((5-AQK_10) < 3, 1, 0) + ifelse((5-AQK_11) < 3, 1, 0) + ifelse(AQK_12 < 3, 1, 0) + ifelse(AQK_13 < 3, 1, 0) + ifelse((5-AQK_14) < 3, 1, 0) + ifelse(AQK_15 < 3, 1, 0) + ifelse((5-AQK_16) < 3, 1, 0) + ifelse((5-AQK_17) < 3, 1, 0) + ifelse((5-AQK_18) < 3, 1, 0) + ifelse(AQK_19 < 3, 1, 0) + ifelse((5-AQK_20) < 3, 1, 0) + ifelse(AQK_21 < 3, 1, 0) + ifelse((5-AQK_22) < 3, 1, 0) + ifelse((5-AQK_23) < 3, 1, 0) + ifelse((5-AQK_24) < 3, 1, 0) + ifelse(AQK_25 < 3, 1, 0) + ifelse((5-AQK_26) < 3, 1, 0) + ifelse(AQK_27 < 3, 1, 0) + ifelse((5-AQK_28) < 3, 1, 0) + ifelse(AQK_29 < 3, 1, 0) + ifelse(AQK_30 < 3, 1, 0) + ifelse((5-AQK_31) < 3, 1, 0) + ifelse((5-AQK_32) < 3, 1, 0) + ifelse((5-AQK_33) < 3, 1, 0))

```

# Introduction

<!-- kickoff -->
Humans in their social environment rely on the information other humans provide. This does not only holds for reading explicit signals, as in conversations, but also for implicit signals, as in gazes. Specifically, if an individual looks into a specific direction, this information is often read and redirects the observers attention towards the referred object or location. The process of following someones gaze is called/can be referred to joint attention. These attentional shifts are crucial for joint attention.  Laboratory studies showed, that joint attention can not only be induced by the gaze [for an detailed overview see: @Frischen2007a], but also from the body or the head itself [@Lawson2016].

<!-- gaze cuing to joint attenion & social attention -->
The most used paradigm to investigate these attentional shifts is the so called gaze-cueing paradigm [@Friesen1998; @Driver1999; @Langton2000]. These studies show that perceived gaze cues lead to a reflexive attentional shift, which results in an processing benefit for that location [for a very recent study see @Langton2017]. Even though gaze cues are crucial for joint attention, it is criticized that among others these studies used isolated heads [@Friesen1998; @Langton2000] or even cartoon heads [@Driver1999; @Ristic2005] as gaze cues, and therefore lack ecological validity [for an overview on ecological validity see: @Risko2012]. For example, in an recent study @Hayward2017 did not find reliable links between classical laboratory gaze cueing tasks and a real social engage.
The relevance/sensibility/focus to ecologically valid stimuli is a core aspect of social attention research, which provides an bigger framework for gaze cueing [@Itier2009]. The research describes attentional consequences of social interactions and focuses often on similarities and differences of different types of social stimuli [@Risko2012]. The types range from real human interactions [for example: @Laidlaw2011, @Freeth2013a] to highly controlled laboratory settings with isolated faces as stimuli [for example: @Langton2017]. The main finding of this research line is, that some research findings related to social stimuli do not extend to the real world and researches must be sensible to these differences when generalizing laboratory findings [@Jarick2015, @Hayward2017, for an overview see: @Risko2016]. 

<!-- social attention -->
To account for the ecological validity of gaze cues @Zwickel2010 conducted a joint attention study with a more naturalistic scenario. First of all, in their study participants had no explicit task to fulfill. @Zwickel2010 argue, that the lack of a specific task results in more naturalistic viewing behavior and therefore adds more ecological vlaidity to the classical gaze cuing paradigms. In this so called free-viewing paradigm they presented their observers multiple scenes for several seconds. The scenes contained a reference, either a person or a loudspeaker, and two objects. One of the objects was referenced either by an oriented person or loudspeaker. They showed that observers spontaneously prioritize the referenced object, but only when it was referenced by the person. The attentional focus of the person in the scene did influence the attentional distribution of the observer. Interestingly, the same was not true for the loudspeaker. So the referenced objects were not just focused because they might have been salient by themselves, but became more salient merely by the persons reference. This finding is in line with predictions by the social attention. First, that social stimuli are prioritized was confirmed by the results, the most prioritized region was still the head of the shown person.Additionally, with regard to joint attention, the referenced object was fixated remarkably earlier, more often and overall longer then the not referenced object. After all, @Zwickel2010 gave strong evidence that joint attention as consequence of the gaze cue happens spontaneously and that it has high relevance in naturalistic situations. 

<!-- research motivation -->
However, this conceptual replication of @Zwickel2010 aims at answering multiple research questions regarding joint and social attention, including the replication of Zwickel and Võ's [-@Zwickel2010] findings and extending this line of research. 
However, @Zwickel2010 had very little power in their study, with n = 16 participants, and used computer generated stimuli. Here, more naturalistic stimuli and a bigger sample size is used. For more naturalistic stimuli real photographs are chosen over computer rendered scenes. As often, by being more naturalistic experimental control is reduced. The consequences are hold to a minimum by producing stimuli the same way (each scene four times, with the individual looking twice to the left and right top each object). Nevertheless, in real photographs small changes are unavoidable. Whereas @Zwickel2010 only rotate the figure in the scene, here another photography was taken. As consequence, for example, the body orientation is not perfectly controlled anymore and might differ slightly between photographs even within scenes. With higher power and more naturalistic stimuli this study will underline @Zwickel2010 findings and tackle the two mentioned flaws. However, in this study we presume that the effect showed by @Zwickel2010 is genuine for social stimuli, therefore there is no non-social condition comparable to the loudspeaker-condition.
In fact, this line of research is being extended. First, the influence of top-down modulations on joint and social attention in naturalistic scenes is investigated. Earlier research showed, that social attention is influenced by multiple factors for example social status [@Foulsham2010] or expectations [@Perez-Osorio2015] of the observer. These studies have in common that they manipulate implicitly the context. 
This is in contrast to this study, where a very explicit manipulation is used. Additionally, consequences for latter cognitive processes, here memory effects, are examined. Therefore half of the observers received the information that a memory test is following before the experimental part (top-down modulation). The other half of the observers did not receive any top-down modulation, just like @Zwickel2010, but did the memory task unannounced after the experimental part.
As @Zwickel2010 showed, persons in scene influence the viewing behavior of observers spontaneously. Here the instruction was thought to influence the viewing behavior, in that sense, that spontaneous viewing behavior will be reduced. It is important to mention, that it is not expected that the influence of the presence of the person would vanish due to top-down modulation, but it is supposed to be be weaker. Effects should be visible regardless for the social attention part and also for the joint attention part of this study.

<!-- Hypothesis -->
<!-- alter baustein: First, for joint attention, it is presumed to replicate the main effects of a persons presence on the observer described by @Zwickel2010. It is therefore hypothesized that the gaze of the person in the scene leads to prioritization for the gazed-at/referenced object. The prioritization can be seen in earlier, more and longer fixations. In line with @Zwickel2010 it is also expected, that saccades leaving from the head are more likely to move to the gazed-at object. -->

<!-- joint attention/gaze following -->
The foundation of this study is to replicate the findings by [@Zwickel2010].
*H1*. Consequently, a prioritization for the gazed-at objects is predicted. In line with @Zwickel2010, this  prioritization can be measured in multiple ways. First there should be an early fixation bias towards the gazed-at object. During presentation time, the total time that the gazed-at object is fixated should be prolonged, with more fixations as well. For saccades it is expected, that saccades leaving from the head are more likely to move to the gazed-at object, in contrast to the not-gazed-at object. *(Main effect icond, Anova)*
*H2*. New, compared to @Zwickel2010's study, is the instruction condition. For gaze-following it is expected that the exclusive prioritization for the gazed-at object will decrease for subjects in explicit-encoding group, due to the explicit processing of the scene. This means smaller differences in the fixation measurements are expected. For leaving saccades it is also expected that the under H1n stated effect decreases. *(1st: Interaction group:icond)*
_(?!Hypothese zu Gruppen, dass explicit mehr focus auf Gegensätnde richtet, da anweisung? (Maineffect group)_
*H3*. Also new is the follow-up memory test for the two potentially gazed-at objects. First it is assumed, that subjects with announced memory test will recall more items, because they process the scenes more thorough. Additionally it is expected, that in the free-recall condition gazed-at objects are better recalled then not-gazed at objects. 

<!-- social attention -->
*H4*. As naturalistic scenes are used, the basic effects of social attention are expected. This means, that the head will be prioritized over the body. This prioritization can be measured, in multiple ways. And again, it is expected, that first fixation fell earlier on the head, that it is fixated longer and more often then the body. Additionally it is also expected, that the fixations occur earlier, then on the gazed-at object, because the gaze-cue needs to be processed in advance.
*H5*. Due to the instruction of the memory test, and the assumed change in processing the picture, the viewing behavior should change for social stimuli. Due to explicit encoding, it is expected that the head looses some of its importance. As a consequence, the head should be prioritized stronger in the free-viewing group compared to the explicit-encoding group. Therefor it should be fixated longer, faster and more often. 

# Methods
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants
In this study `r length(df.w.demo$vp)` observers (`r length(df.w.demo$sex[df.w.demo$sex==1])` female and `r length(df.w.demo$sex[df.w.demo$sex!=1])` male) between `r min(df.w.demo$age)` and `r max(df.w.demo$age)` years (M = `r round(mean(df.w.demo$age),2)`, SD = `r round(sd(df.w.demo$age),2)`) participated voluntarily. All observer had normal or corrected vision and were recruited at the University of Würzburgs online subject pool or by blackboard. For participation observers received study credit or 5€. One observer was excluded due to missing data.

## Stimuli and Apparatus
The experimental stimuli consisted 26 different scenes with a single individual in the center looking at one of two objects of interests in the right or left half of the photography. The direction of the gaze cue and the place of the objects were balanced, creating 104 unique naturalistic scenes in the end. For each participant, a set was randomly generated from this pool containing each scene only once, resulting in 26 trials with exclusive scenes. Eye movements were recorded with an EyeLink1000
tower system, sampling at 1000 Hz.

## Design & Procedure
A two-level (instruction: free viewing/ explicit encoding) between subjects factor and a two-level (reference: cued/uncued) within subjects factor was manipulated in the experiment. After giving full informed consent, the eye-tracker was calibrated for each observer. Observers were then told either that there is a follow-up memory test or nothing. The presentation of the stimuli was randomized. In each trial the scene was present for 10 seconds. Observers were told to look at the scene as they would look at photographs. Inter trial interval was randomized between 2 and 4 seconds. After the last trial participants filled in questionnaires (demographics, autism-questionnaire (short), and Inventar soziale kompetenz) and were asked to recall as many items as possible in a free recall memory-test. Afterwards participants received their credit.


## Data analysis
Regions-of-Interest were hand-drawn around the relevant objects and the face and body of the individual in the center. These ROIs were color-coded for cued and uncued objects and also for the head and body of the individual on the photography to determine gaze locations. Outlier detection.

`r cite_r("r-references.bib")` is used for all analyses.


# Results
Prioritization of the ROIs in the scene were measured in multiple ways. 

## Joint attention/ gaze following

As a measure of prioritization fixation duration, fixation number, fixation latency, as well as leaving saccades are used.

### Fixations
```{r TO-DO: Plots fixations joint, warining = FALSE, message = FALSE}

```

```{r Descriptives fixations joint, warining = FALSE, message = FALSE}

# Descriptives for fixation chacracteristics for joint attention

dscr.fixjoi <- df.w.et %>% summarise(mean(fix.gaze), sd(fix.gaze), mean(fix.nongaze), sd(fix.nongaze), mean(fixn.gaze), sd(fixn.gaze), mean(fixn.nongaze), sd(fixn.nongaze), mean(fixlat.gaze), mean(fixlat.nongaze), sd(fixlat.nongaze))
dscr.fixjoi.group <- df.w.et %>% group_by(group) %>% summarise(mean(fix.gaze), sd(fix.gaze), mean(fix.nongaze), sd(fix.nongaze), mean(fixn.gaze), sd(fixn.gaze), mean(fixn.nongaze), sd(fixn.nongaze), mean(fixlat.gaze), sd(fixlat.gaze), mean(fixlat.nongaze), sd(fixlat.nongaze))

```

```{r Anova fixations joint, warning = FALSE, message = FALSE}

# ANOVA Fixations characteristics for joint attention
## 2 (Group) x 2 (Gaze) ANOVA

icond <- gl(2,1,labels=c("cued","uncued")) # within-factor
idata <- data.frame(icond)

for (st in seq(7,16,4)) { # Variables 7:16, every 4th: fix.gaze and fix.nogaze; fixn.gaze and ...
  carmod <- lm(as.matrix(df.w.et[,st:(st+1)]) ~ df.w.et$group)
  #print(colnames(df.w.et[,st:(st+1)]))
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }

rm(carmod, idata, icond, st)

```

#### Fixation duration (H1, H2)
The relative cumulative fixation duration is calculated as time duration on an OOI divided by the time spent fixating the rest of the scene. It shows a bias towards the gazed-at object, which was fixated significantly longer (see Table/Figure) and confirms [@Zwickel2010]'s findings. As predicted the corresponding ANOVA revealed a significant main effect for reference, `r apa.anova.fix.gaze$full_result$icond` and for condition `r apa.anova.fix.gaze$full_result$df_w_et_group`. Against prediction their was no effect of the two-way interaction, `r apa.anova.fix.gaze$full_result$df_w_et_group_icond`.


#### Fixation latency (H1, H2)
An additional measurement of prioritization is fixation latency, that is for each OOI  the mean out of all first fixations after stimulus onset. In line with [@Zwickel2010], an object is fixated earlier when it is gazed-at. But also when the observer was in the explicit encoding condition. The statistical significance is confirmed by an ANOVA: for reference `r apa.anova.fixlat.gaze$full_result$icond` and condition, `r apa.anova.fixlat.gaze$full_result$df_w_et_group`). For fixation latency with a trend(?) for an interaction, `r apa.anova.fixlat.gaze$full_result$df_w_et_group_icond`.

#### Fixation number (H1, H2)
As a third measurement of prioritization, fixation number, as the count of fixations per ROI during scene presentation, divided by the total number of fixations during scene presentation, was calculated. It shows, that OOI were fixated more often when gazed-at `r apa.anova.fixn.gaze$full_result$icond`, again in line with [@Zwickel2010]. Objects were also more often fixated in the explicit encoding condition`r apa.anova.fixn.gaze$full_result$df_w_mem`, and again against prediction there was no interaction, `r apa.anova.fixn.gaze$full_result$df_w_et_group_icond`.
 

### Saccades

```{r plots saccade}

# Plots: Saccade data
farben <- c("blue","yellow")
ttxt <- c("Person","Face","Body")

for (i in 1:3) {
  st <- (17:19)[i]

  # Fixation density
  m  <- cbind(apply(df.w.et[df.w.et$group=="free",c(st,st+3)],2,mean),
              apply(df.w.et[df.w.et$group=="mem",c(st,st+3)],2,mean))
  se <- cbind(apply(df.w.et[df.w.et$group=="free",c(st,st+3)],2,sd)/sqrt(sum(df.w.et$group=="free")),
              apply(df.w.et[df.w.et$group=="mem",c(st,st+3)],2,sd)/sqrt(sum(df.w.et$group=="mem")))

  yrng <- c(0,max(m+se))

  x <- barplot(m,beside=TRUE,col=farben,ylim=yrng,xlab="",ylab="% of total fixation time")
  arrows(x,m-se,x,m+se,length=0.03,angle=90,code=3,col="black")
  axis(1,apply(x,2,mean),c("Free viewing","Explicit encoding"),tick=FALSE)

  title(ttxt[i])
}

legend(max(x),max(yrng),c("Cued","Uncued"),fill=farben,xjust=1,yjust=1)

rm(m, se, yrng, x, st, farben, ttxt, i)

```

```{r Anova saccades, warning=FALSE, message=FALSE}
# ANOVA Saccades
## 2 (Group) x 2 (Gaze) ANOVA

icond <- gl(2,1,labels=c("cued","uncued")) # within-factor
idata <- data.frame(icond)

for (st in 17:19) {
  carmod <- lm(as.matrix(df.w.et[,c(st,(st+3))]) ~ df.w.et$group)
  #print(colnames(df.w.et[,c(st,(st+3))]))
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }

dscr.sac <- df.w.et %>% summarise(mean(sac.pgaze), sd(sac.pgaze), mean(sac.pnongaze), sd(sac.pnongaze), mean(sac.fgaze), sd(sac.fgaze), mean(sac.fnongaze), sd(sac.fnongaze), mean(sac.bgaze), sd(sac.bgaze), mean(sac.bnongaze), sd(sac.bnongaze))

dscr.sac.group <- df.w.et %>% group_by(group) %>% summarise(mean(sac.pgaze), sd(sac.pgaze), mean(sac.pnongaze), sd(sac.pnongaze), mean(sac.fgaze), sd(sac.fgaze), mean(sac.fnongaze), sd(sac.fnongaze), mean(sac.bgaze), sd(sac.bgaze), mean(sac.bnongaze), sd(sac.bnongaze))

rm(carmod, idata, icond, st)
```

#### Leaving saccades (H1, H2)
The second hypothesis predicts, that there are more saccades leaving from the head to the gazed-at object. Furthermore it is claimed, that an interaction between instruction and reference results in increasing differences in the free-viewing condition. An Anova supports the first claim. There is an significant main effect for reference, `r apa.anova.sac.fgaze$full_result$icond`, and also for group,  `r apa.anova.sac.fgaze$full_results$df_w_et_group`. No confirmation was found for the predicted interaction between reference and instruction `r apa.anova.sac.fgaze$full_result$df_w_et_group_icond`.

### Memory (H3)

```{r Anova memory, warning=FALSE, message=FALSE}
# Recalled items
# 2 (Condition) x 2 (Gaze) ANOVA (auf erinnerte Details)

imem <- gl(2,1,labels=c("cued","uncued"))
idata <- data.frame(imem)

# Car
carmod <- lm(as.matrix(df.w.mem[,3:4]) ~ df.w.mem$bed)
# print(colnames(df.w.mem[c(3,4)]))
#print(Anova(carmod, idata=idata, idesign=~imem, type="III"))
anova.mem <- Anova(carmod, idata=idata, idesign=~imem, type="III")
apa.anova.mem <- apa_print(Anova(carmod, idata=idata, idesign=~imem, type="III"), correction="GG", mse = FALSE)

dscr.mem <- df.w.mem %>% summarise(mean(memgaze), sd(memgaze), mean(memnogaze), sd(memnogaze))
dscr.mem.group <- df.w.mem %>% group_by(bed) %>% summarise(mean(memgaze), sd(memgaze), mean(memnogaze), sd(memnogaze))

rm(imem, idata, carmod)
```
The free-recall test showed, that unsurprisingly observers with explicit encoding remembered on average 2 items more then observers from the other group. An Anova proved this effect as statistically significant, `r apa.anova.mem$full_result$df_w_mem_bed`. Referencing an OOI did not influence memory performance, `r apa.anova.mem$full_result$imem`. There was also no interaction, `r apa.anova.mem$full_result$df_w_mem_bed_imem`.


## Social attention
A similar pattern to the OOI can be seen when comparing the head with the body region. Again there were the same measurements to account for prioritization. 

```{r TO-DO: Plots fixations social, warining = FALSE, message = FALSE}

```

```{r Descriptives fixations social, warining = FALSE, message = FALSE}

# Descriptives for fixation chacracteristics for social attention

dscr.fixsoc <- df.w.et %>% summarise(mean(fix.face), sd(fix.face), mean(fix.body), sd(fix.body), mean(fixn.face), sd(fixn.face), mean(fixn.body), sd(fixn.body), mean(fixlat.face), sd(fixlat.face), mean(fixlat.body), sd(fixlat.body))
dscr.fixsoc.group <- df.w.et %>% group_by(group) %>% summarise(mean(fix.face), sd(fix.face), mean(fix.body), sd(fix.body), mean(fixn.face), sd(fixn.face), mean(fixn.body), sd(fixn.body), mean(fixlat.face), sd(fixlat.face), mean(fixlat.body), sd(fixlat.body))
```

```{r Anova fixations social, warning = FALSE, message = FALSE}
# ANOVA Fixations characteristics
## 2 (Group) x 2 (Face/Body) ANOVA

icond <- gl(2,1,labels=c("head","body")) # within-factor
idata <- data.frame(icond)

for (st in seq(5,16,4)) { # Variables 5:16, every 4th: fix.face and fix.noface; fixn.face and ...
    carmod <- lm(as.matrix(df.w.et[,st:(st+1)]) ~ df.w.et$group)
  #print(Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("anova.",colnames(df.w.et)[st]), Anova(carmod, idata=idata, idesign=~icond, type="III"))
  assign(paste0("apa.anova.",colnames(df.w.et)[st]), apa_print(Anova(carmod, idata=idata, idesign=~icond, type="III"), correction="GG", mse = FALSE))
  }


rm(carmod, idata, icond, st)

```
Analysis for the social attention part contained again Anovas for the different dependent variables indicating prioritization.

### Face vs body fixation (H4)
The first measurement shows, that faces were fixated longer then the body  (Table X), `r apa.anova.fix.face$full_result$icond`, but there is no difference between the instruction-groups, `r apa.anova.fix.face$full_result$df_w_et_group`, and no interaction (trend) between the two factors, `r apa.anova.fix.face$full_result$df_w_et_group_icond`.
The same pattern can be seen for fixation number, where there is a strong effect for region, with more fixations on the face, `r apa.anova.fixn.face$full_result$icond` and no difference between the instructions, `r apa.anova.fixn.face$full_result$df_w_et_group`, and no interaction `r apa.anova.fixn.face$full_result$df_w_et_group_icond`.
Latencies of fixation differed also remarkably between head and body, but only for region `r apa.anova.fixlat.face$full_result$icond`. There was neither an effect for instruction, `r apa.anova.fixlat.face$full_result$df_w_et_group` nor was their an interaction, `r apa.anova.fixlat.face$full_result$df_w_et_group_icond`.

### Free-viewing vs explicit-encoding face fixations (H5)
```{r Plots free vs mem face fixations, warning = FALSE, message = FALSE}

# plots

plot.face.free_vs_mem <- df.l.et %>%
  filter(fixations=="fix" & region=="face") %>%
  ggboxplot(x = "fixations", y = "value",
                color = "group", palette =c("#00AFBB", "#E7B800", "#FC4E07"),
                add = "jitter", shape = "group") #+
  #stat_compare_means()
plot.face.free_vs_mem

```

```{r T-test face fixations, warning = FALSE, message = FALSE}

# Fixations Face in Free Viewing vs. Explicit Encoding

for (st in seq(5,16,4)) {
  msd <- c(mean(df.w.et[df.w.et$group=="free",st]),sd(df.w.et[df.w.et$group=="free",st]),
           mean(df.w.et[df.w.et$group=="mem",st]),sd(df.w.et[df.w.et$group=="mem",st]))
  teststat <- t.test(df.w.et[,st] ~ df.w.et$group)
  
  assign(paste0("ttest.",colnames(df.w.et)[st]), data.frame(M.free=msd[1],SD.free=msd[2], M.mem=msd[3], SD.mem=msd[4],  df=teststat$parameter, t=teststat$statistic, p=teststat$p.value))
 
  assign(paste0("apa.ttest.",colnames(df.w.et)[st]), apa_print(t.test(df.w.et[,st] ~ df.w.et$group)))
  }


rm(msd, teststat, st) 

```

A t-test between face fixation for the different groups provides information whether faces are differently processed dependent on the instruction observers get. Only fixation latency differed significantly between groups, `r apa.ttest.fixlat.face$full_result`, with faster fixations for the free viewing group. For fixation duration there was only a trend for difference between groups, `r apa.ttest.fix.face$full_result`. And fixation number did not differ, `r apa.ttest.fixn.face$full_result`.   

# Discussion

The main attempt to replicate @Zwickel2010 's findings was successful. A strong preference for the gaze-at object can be seen in a lower latency until first fixation, longer fixation duration and more frequent fixations, just like @Zwickel2010 demonstrated in their study. This finding puts more evidence on the idea that the viewing behavior is heavily but spontaneously influenced by persons in a scene.
This research is extended by the given study by an explicit task concerning the given scene. 

## joint attention


## social attention




\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
